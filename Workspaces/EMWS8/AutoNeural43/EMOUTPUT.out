*------------------------------------------------------------*
User:                Lukas Fahr
Date:                28. April 2016
Time:                10.58 Uhr
*------------------------------------------------------------*
* Training Output
*------------------------------------------------------------*
 
 
 
 
Variable Summary
 
            Measurement    Frequency
Role           Level         Count
 
INPUT        BINARY             6
INPUT        INTERVAL          15
INPUT        NOMINAL            2
REJECTED     BINARY             1
REJECTED     INTERVAL           9
TARGET       BINARY             1
 
 
 
 
Model Events
 
                                  Number
                   Measurement      of
Target    Event       Level       Levels      Order       Label
 
DepVar      1        BINARY          2      Descending    DepVar
 
 
 
 
Predicted and decision variables
 
Type         Variable     Label
 
TARGET       DepVar       DepVar
PREDICTED    P_DepVar1    Predicted: DepVar=1
RESIDUAL     R_DepVar1    Residual: DepVar=1
PREDICTED    P_DepVar0    Predicted: DepVar=0
RESIDUAL     R_DepVar0    Residual: DepVar=0
FROM         F_DepVar     From: DepVar
INTO         I_DepVar     Into: DepVar
 
 
 
 
Search # 1 FUNNEL LAYERS trial # 1 : DIRECT : Training
 
_ITER_     _AIC_     _AVERR_     _MISC_    _VAVERR_    _VMISC_
 
   0      2077.06    0.42482    0.15122     0.42661    0.15226
   1       962.84    0.19015    0.06318     0.20530    0.07466
   2       751.79    0.14570    0.06024     0.15522    0.06876
   3       736.72    0.14253    0.05897     0.15054    0.07073
   4       736.34    0.14245    0.05897     0.15095    0.06876
   5       736.07    0.14239    0.05939     0.15058    0.06974
   6       736.00    0.14238    0.05897     0.15075    0.06680
   7       735.96    0.14237    0.05897     0.15062    0.06974
   8       735.95    0.14237    0.05897     0.15069    0.06680
   9       735.95    0.14236    0.05897     0.15064    0.06974
  10       735.94    0.14236    0.05897     0.15067    0.06778
  11       735.94    0.14236    0.05897     0.15065    0.06974
  12       735.94    0.14236    0.05897     0.15067    0.06778
  13       735.94    0.14236    0.05897     0.15066    0.06974
  14       735.94    0.14236    0.05897     0.15066    0.06876
  14       735.94    0.14236    0.05897     0.15066    0.06876
 
 
 
 
Selected Iteration based on _VMISC_
 
_ITER_     _AIC_     _AVERR_     _MISC_     _VAVERR_     _VMISC_
 
   6      736.001    0.14238    0.058972     0.15075    0.066798
 
 
 
 
Search # 1 FUNNEL LAYERS trial # 2 : LOGISTIC : Prelim
 
The NEURAL Procedure
 
Preliminary       Starting         Objective         Number
 Training          Random           Function           of        Terminating
    Run             Seed             Value         Iterations     Criteria
 
        1          1099492053    0.078944362161           25
        2           891921759    0.063185506338           25
        3          2015235829    0.073494106413           25
        4          1073240799    0.062195848183           25
        5          1707466566    0.068752759032           25
        6          1863809418    0.059485279649           25
        7          1348406820    0.056063640417           25
        8           313319148    0.068240413839           25
        9           547243750    0.046743218891           25
       10          1223236922    0.059857736484           25
       11           835211555    0.066635669598           25
       12          1153017962    0.056660073514           25
       13           377277272    0.066904694657           25
       14           661273683    0.076824089829           25
       15           494243336    0.047836240813           25
       16          1812447560    0.060723131751           25
       17           533226925    0.050536111647           25
       18           280112036    0.087501354133           25
       19          1883108708    0.068487791433           25
       20          2017365357     0.06312115458           25
       21          1651978579     0.07144719025           25
       22          2056800742    0.055002421374           25
       23          1057513943    0.073852900588           25
       24          1185960805     0.06429991833           25
       25          2045224558    0.063389949513           25
       26           229538298    0.047005949047           25
       27          2079526044    0.068993306601           25
       28          1971561506    0.054159769365           25
 
 
 
 
Search # 1 FUNNEL LAYERS trial # 2 : LOGISTIC : Training
 
_ITER_     _AIC_      _AVERR_     _MISC_     _VAVERR_     _VMISC_
 
   0      657.937    0.046743    0.018534     0.20627    0.056974
   1      655.179    0.046162    0.017692     0.20626    0.058939
   2      650.044    0.045081    0.017270     0.20352    0.057957
   3      648.294    0.044712    0.017270     0.20218    0.058939
   4      642.797    0.043554    0.015586     0.20360    0.058939
   5      634.769    0.041864    0.013058     0.20336    0.058939
   6      630.684    0.041003    0.013058     0.20173    0.056974
   7      625.038    0.039814    0.012216     0.20167    0.054028
   8      618.215    0.038377    0.012637     0.20045    0.055992
   9      615.500    0.037805    0.014743     0.19284    0.057957
  10      610.861    0.036828    0.014322     0.19560    0.058939
  11      607.705    0.036164    0.013058     0.20261    0.056974
  12      603.206    0.035216    0.012216     0.19858    0.055010
  13      597.947    0.034109    0.010952     0.19928    0.055992
  14      595.770    0.033650    0.010531     0.21087    0.054028
  15      591.231    0.032694    0.009267     0.20639    0.056974
  16      589.324    0.032292    0.008425     0.21565    0.056974
  17      584.889    0.031358    0.008846     0.21370    0.057957
  18      580.225    0.030376    0.008846     0.22323    0.055992
  19      578.160    0.029941    0.006318     0.22039    0.055010
  20      574.740    0.029221    0.006740     0.22232    0.056974
  21      572.490    0.028747    0.007161     0.22611    0.056974
  22      568.677    0.027944    0.005897     0.22617    0.058939
  23      567.067    0.027605    0.006740     0.22955    0.055010
  24      564.483    0.027060    0.005897     0.22885    0.055010
  25      562.122    0.026563    0.005055     0.22969    0.055010
  26      558.541    0.025809    0.005055     0.23246    0.055010
  27      556.052    0.025285    0.006318     0.23822    0.054028
  28      553.337    0.024713    0.004634     0.23843    0.055010
  29      549.430    0.023890    0.004634     0.24052    0.056974
  30      546.805    0.023337    0.004212     0.25602    0.058939
  31      543.274    0.022593    0.004634     0.24903    0.057957
  32      540.055    0.021916    0.005055     0.25435    0.056974
  33      538.910    0.021674    0.003791     0.25216    0.057957
  34      536.143    0.021092    0.002949     0.25441    0.057957
  35      533.815    0.020601    0.003370     0.26385    0.061886
  36      532.658    0.020358    0.003370     0.25494    0.057957
  37      530.709    0.019947    0.003370     0.26061    0.058939
  38      529.139    0.019617    0.003370     0.27584    0.062868
  39      526.746    0.019113    0.003370     0.27088    0.061886
  40      526.131    0.018983    0.003791     0.27688    0.061886
  41      524.402    0.018619    0.003791     0.27442    0.061886
  42      521.907    0.018093    0.003370     0.28433    0.064833
  43      519.717    0.017632    0.003791     0.29656    0.065815
  44      517.553    0.017176    0.004634     0.28677    0.065815
  45      516.051    0.016860    0.003791     0.29622    0.065815
  46      514.151    0.016460    0.002949     0.30303    0.063851
  47      512.100    0.016028    0.003370     0.29513    0.064833
  48      510.137    0.015614    0.003791     0.30487    0.064833
  49      508.206    0.015208    0.002949     0.30124    0.064833
  50      506.584    0.014866    0.002527     0.30939    0.062868
  50      506.584    0.014866    0.002527     0.30939    0.062868
 
 
 
 
Selected Iteration based on _VMISC_
 
_ITER_     _AIC_      _AVERR_     _MISC_     _VAVERR_     _VMISC_
 
   7      625.038    0.039814    0.012216     0.20167    0.054028
 
 
 
 
Search # 1 FUNNEL LAYERS trial # 3 : SINE : Prelim
 
The NEURAL Procedure
 
Preliminary       Starting         Objective         Number
 Training          Random           Function           of        Terminating
    Run             Seed             Value         Iterations     Criteria
 
        1          1099492053    0.064248258522           25
        2           891921759    0.079267033462           25
        3          2015235829    0.073958459199           25
        4          1073240799    0.077474164562           25
        5          1707466566    0.075305675254           25
        6          1863809418    0.067587968224           25
        7          1348406820    0.067351077304           25
        8           313319148    0.069104650611           25
        9           547243750    0.070287043469           25
       10          1223236922    0.079406503757           25
       11           835211555    0.062141955859           25
       12          1153017962    0.071498523064           25
       13           377277272    0.071490148588           25
       14           661273683    0.069431373217           25
       15           494243336    0.078848098169           25
       16          1812447560    0.077650593928           25
       17           533226925    0.068550573927           25
       18           280112036    0.073432864263           25
       19          1883108708    0.063632413767           25
       20          2017365357    0.072251639217           25
       21          1651978579    0.079190633196           25
       22          2056800742    0.070628472934           25
       23          1057513943     0.06711291445           25
       24          1185960805    0.077635271481           25
       25          2045224558    0.089764516589           25
       26           229538298    0.066343756543           25
       27          2079526044    0.076023394917           25
       28          1971561506    0.063860082411           25
 
 
 
 
Search # 1 FUNNEL LAYERS trial # 3 : SINE : Training
 
_ITER_     _AIC_      _AVERR_     _MISC_     _VAVERR_     _VMISC_
 
   0      731.050    0.062142    0.022325     0.13199    0.055010
   1      727.214    0.061334    0.021904     0.13256    0.053045
   2      724.986    0.060865    0.022325     0.13313    0.054028
   3      721.760    0.060185    0.021483     0.13358    0.056974
   4      720.270    0.059872    0.022325     0.13314    0.056974
   5      717.876    0.059367    0.021483     0.13137    0.053045
   6      716.240    0.059023    0.021483     0.12907    0.054028
   7      714.562    0.058669    0.021483     0.12756    0.052063
   8      710.142    0.057738    0.021483     0.12615    0.051081
   9      708.277    0.057346    0.021483     0.12103    0.053045
  10      705.351    0.056729    0.021904     0.12149    0.052063
  11      703.353    0.056309    0.021061     0.11998    0.053045
  12      700.699    0.055750    0.021061     0.11891    0.052063
  13      698.773    0.055344    0.020219     0.11773    0.048134
  14      696.512    0.054868    0.019377     0.11948    0.049116
  15      692.765    0.054079    0.019798     0.12167    0.052063
  16      690.629    0.053629    0.018113     0.12442    0.054028
  17      687.999    0.053075    0.019377     0.12324    0.054028
  18      684.861    0.052414    0.016428     0.12209    0.052063
  19      683.581    0.052144    0.017692     0.12710    0.049116
  20      681.474    0.051700    0.016007     0.12465    0.050098
  21      679.417    0.051267    0.015586     0.12162    0.047151
  22      676.236    0.050597    0.016007     0.12265    0.046169
  23      673.940    0.050114    0.015586     0.12641    0.048134
  24      671.855    0.049675    0.017270     0.12609    0.046169
  25      668.780    0.049027    0.015586     0.12920    0.048134
  26      666.636    0.048575    0.016007     0.13502    0.049116
  27      663.873    0.047993    0.015164     0.13227    0.049116
  28      661.377    0.047468    0.015586     0.13753    0.049116
  29      659.453    0.047062    0.014743     0.13265    0.048134
  30      656.424    0.046425    0.013479     0.13816    0.048134
  31      654.877    0.046099    0.013901     0.14902    0.053045
  32      652.237    0.045543    0.012216     0.14341    0.052063
  33      649.116    0.044886    0.014322     0.14169    0.053045
  34      647.443    0.044533    0.013058     0.14634    0.057957
  35      644.577    0.043930    0.013058     0.14826    0.057957
  36      642.905    0.043577    0.013479     0.15658    0.060904
  37      640.071    0.042981    0.013058     0.15076    0.058939
  38      636.126    0.042150    0.013058     0.14760    0.056974
  39      633.588    0.041615    0.013479     0.14605    0.055010
  40      630.598    0.040985    0.011794     0.15498    0.059921
  41      629.032    0.040656    0.012216     0.15621    0.055992
  42      626.622    0.040148    0.011794     0.15443    0.055992
  43      625.636    0.039940    0.012637     0.15970    0.058939
  44      622.810    0.039345    0.011794     0.15526    0.059921
  45      619.520    0.038652    0.010952     0.16652    0.059921
  46      618.278    0.038390    0.011794     0.15767    0.055010
  47      614.293    0.037551    0.011794     0.16382    0.059921
  48      611.584    0.036981    0.010531     0.16881    0.062868
  49      609.687    0.036581    0.010110     0.16829    0.061886
  50      607.889    0.036202    0.011373     0.16726    0.058939
  50      607.889    0.036202    0.011373     0.16726    0.058939
 
 
 
 
Selected Iteration based on _VMISC_
 
_ITER_     _AIC_      _AVERR_     _MISC_     _VAVERR_     _VMISC_
 
  22      676.236    0.050597    0.016007     0.12265    0.046169
 
 
 
 
Search # 1 FUNNEL LAYERS trial # 4 : SOFTMAX : Prelim
 
The NEURAL Procedure
 
Preliminary       Starting         Objective         Number
 Training          Random           Function           of        Terminating
    Run             Seed             Value         Iterations     Criteria
 
        1          1452355784    0.061485375259           25
        2          1161293754    0.080509404296           25
        3           796374574     0.08247877611           25
        4          1807677195    0.078477001397           25
        5           957239873    0.065630055512           25
        6          1501007047     0.07200208879           25
        7          1863809418    0.076900735249           25
        8          1007790070    0.058068538049           25
        9          1350652522    0.066311940918           25
       10           856260411    0.064284752142           25
       11           688055046    0.083117536958           25
       12            93168191    0.068633774162           25
       13          1753811624    0.075942839081           25
       14          1153017962    0.072356053185           25
       15          1565665753    0.055980853601           25
       16           449557442    0.072685562698           25
       17           811568573    0.066275758444           25
       18          2116035701    0.088300160245           25
       19            81185031    0.046902825526           25
       20           282775567    0.054123811664           25
       21           280112036     0.06761456737           25
       22           811610307    0.060514159198           25
       23          1672787586    0.056254135009           25
       24          1587724599    0.064948074394           25
       25           381699039    0.050523449446           25
       26            50530920    0.075778915671           25
       27           958935477    0.071464395098           25
       28          1185960805    0.075954672632           25
 
 
 
 
Search # 1 FUNNEL LAYERS trial # 4 : SOFTMAX : Training
 
_ITER_     _AIC_      _AVERR_     _MISC_     _VAVERR_     _VMISC_
 
   0      598.695    0.046903    0.014743     0.19963    0.049116
   1      597.806    0.046716    0.014322     0.19939    0.049116
   2      594.675    0.046056    0.016428     0.19799    0.049116
   3      591.926    0.045477    0.015586     0.19503    0.049116
   4      590.786    0.045237    0.014322     0.19191    0.049116
   5      588.002    0.044651    0.013901     0.18559    0.046169
   6      586.662    0.044369    0.013479     0.18443    0.045187
   7      584.381    0.043888    0.013058     0.18190    0.046169
   8      582.786    0.043552    0.012637     0.18041    0.047151
   9      580.704    0.043114    0.012637     0.18279    0.047151
  10      578.166    0.042579    0.012637     0.18487    0.045187
  11      575.581    0.042035    0.011373     0.19120    0.044204
  12      572.937    0.041478    0.011794     0.19259    0.044204
  13      569.088    0.040667    0.011794     0.19826    0.045187
  14      567.424    0.040317    0.012637     0.20305    0.045187
  15      566.719    0.040168    0.013479     0.20847    0.042240
  16      564.065    0.039609    0.011794     0.20163    0.045187
  17      560.412    0.038840    0.010952     0.20365    0.045187
  18      558.811    0.038503    0.010952     0.19978    0.050098
  19      556.303    0.037974    0.010952     0.20058    0.049116
  20      553.951    0.037479    0.010531     0.20115    0.050098
  21      550.784    0.036812    0.010531     0.19910    0.051081
  22      549.036    0.036444    0.010110     0.19892    0.051081
  23      548.294    0.036288    0.010110     0.20166    0.048134
  24      546.062    0.035818    0.009267     0.20329    0.050098
  25      543.501    0.035278    0.008425     0.21321    0.052063
  26      541.611    0.034880    0.008846     0.22026    0.050098
  27      539.739    0.034486    0.008425     0.22124    0.053045
  28      539.180    0.034368    0.008846     0.23536    0.053045
  29      537.557    0.034026    0.008846     0.22839    0.055010
  30      536.466    0.033796    0.008425     0.23119    0.053045
  31      533.501    0.033172    0.008425     0.24313    0.051081
  32      531.783    0.032810    0.008003     0.24063    0.050098
  33      529.941    0.032422    0.009267     0.24928    0.050098
  34      527.663    0.031942    0.008846     0.26003    0.051081
  35      524.635    0.031305    0.008846     0.26970    0.051081
  36      523.450    0.031055    0.008003     0.27720    0.051081
  37      521.388    0.030621    0.007161     0.28332    0.053045
  38      518.609    0.030036    0.008003     0.28984    0.051081
  39      517.834    0.029872    0.008846     0.29080    0.052063
  40      516.797    0.029654    0.008003     0.29769    0.053045
  41      515.402    0.029360    0.008846     0.30417    0.050098
  42      514.825    0.029239    0.008846     0.30975    0.051081
  43      514.026    0.029070    0.009267     0.30879    0.053045
  44      512.812    0.028815    0.008425     0.31346    0.051081
  45      512.180    0.028682    0.009267     0.31948    0.050098
  46      511.151    0.028465    0.008846     0.32309    0.051081
  47      510.705    0.028371    0.009688     0.33668    0.053045
  48      509.997    0.028222    0.009267     0.33171    0.052063
  49      509.440    0.028104    0.008425     0.32836    0.053045
  50      508.642    0.027936    0.008425     0.33180    0.050098
  50      508.642    0.027936    0.008425     0.33180    0.050098
 
 
 
 
Selected Iteration based on _VMISC_
 
_ITER_     _AIC_      _AVERR_     _MISC_     _VAVERR_     _VMISC_
 
  15      566.719    0.040168    0.013479     0.20847    0.042240
 
 
 
 
Search # 2 FUNNEL LAYERS trial # 1 : DIRECT : Prelim
 
The NEURAL Procedure
 
Preliminary       Starting         Objective         Number
 Training          Random           Function           of        Terminating
    Run             Seed             Value         Iterations     Criteria
 
        1               12345    0.029287350383           25
 
 
 
 
Search # 2 FUNNEL LAYERS trial # 1 : DIRECT : Training
 
_ITER_     _AIC_      _AVERR_        _MISC_    _VAVERR_     _VMISC_
 
   0      573.056    0.029287    .008845830     0.28874    0.054028
   1      572.655    0.029203    .009688290     0.28885    0.053045
   2      571.749    0.029012    .008003370     0.28927    0.052063
   3      571.392    0.028937    .008003370     0.28853    0.052063
   4      570.636    0.028778    .007582140     0.28750    0.055010
   5      569.757    0.028592    .007582140     0.28740    0.053045
   6      569.250    0.028486    .006739680     0.28888    0.055010
   7      568.511    0.028330    .006739680     0.28758    0.055010
   8      568.148    0.028254    .007160910     0.28687    0.052063
   9      567.696    0.028158    .006739680     0.28755    0.052063
  10      567.034    0.028019    .006739680     0.28905    0.053045
  11      566.749    0.027959    .006739680     0.29045    0.049116
  12      566.071    0.027816    .006739680     0.28876    0.051081
  13      565.341    0.027662    .007160910     0.28826    0.052063
  14      564.858    0.027561    .007582140     0.28716    0.051081
  15      563.700    0.027317    .007160910     0.28404    0.048134
  16      563.166    0.027204    .007582140     0.28220    0.049116
  17      562.975    0.027164    .006318450     0.28276    0.052063
  18      562.490    0.027062    .007582140     0.28280    0.051081
  19      561.521    0.026858    .007160910     0.28371    0.051081
  20      561.105    0.026770    .005897220     0.28204    0.051081
  21      560.074    0.026553    .006739680     0.28189    0.050098
  22      558.930    0.026312    .005897220     0.28150    0.049116
  23      558.396    0.026200    .005897220     0.28304    0.049116
  24      557.041    0.025914    .005897220     0.28576    0.051081
  25      556.195    0.025736    .005897220     0.28921    0.051081
  26      555.540    0.025598    .006739680     0.28901    0.053045
  27      554.623    0.025405    .006739680     0.29032    0.052063
  28      553.499    0.025168    .007160910     0.29062    0.052063
  29      552.921    0.025047    .007582140     0.28941    0.052063
  30      552.074    0.024868    .007582140     0.28810    0.052063
  31      551.790    0.024808    .007160910     0.28592    0.052063
  32      550.993    0.024640    .007160910     0.28528    0.052063
  33      550.715    0.024582    .007160910     0.29018    0.049116
  34      549.701    0.024368    .006739680     0.28593    0.050098
  35      549.013    0.024223    .006739680     0.28589    0.049116
  36      548.089    0.024029    .005897220     0.28910    0.047151
  37      547.815    0.023971    .006739680     0.29366    0.049116
  38      546.857    0.023769    .005897220     0.29103    0.047151
  39      545.566    0.023498    .006318450     0.29536    0.048134
  40      544.787    0.023333    .006318450     0.29613    0.047151
  41      543.022    0.022962    .005475990     0.29907    0.045187
  42      541.890    0.022723    .006318450     0.29624    0.048134
  43      541.445    0.022629    .005475990     0.30036    0.046169
  44      540.732    0.022479    .005475990     0.29937    0.046169
  45      540.179    0.022363    .005897220     0.29913    0.047151
  46      538.968    0.022108    .005897220     0.29945    0.048134
  47      537.608    0.021821    .006318450     0.30120    0.048134
  48      537.141    0.021723    .006318450     0.30294    0.048134
  49      536.338    0.021554    .006318450     0.30761    0.048134
  50      535.038    0.021280    .005475990     0.31381    0.047151
  50      535.038    0.021280    .005475990     0.31381    0.047151
 
 
 
 
Selected Iteration based on _VMISC_
 
_ITER_     _AIC_      _AVERR_        _MISC_    _VAVERR_     _VMISC_
 
  41      543.022    0.022962    .005475990     0.29907    0.045187
 
 
 
 
Search # 2 FUNNEL LAYERS trial # 2 : LOGISTIC : Prelim
 
The NEURAL Procedure
 
Preliminary       Starting         Objective         Number
 Training          Random           Function           of        Terminating
    Run             Seed             Value         Iterations     Criteria
 
        1           597562455    0.057111519312           25
        2          1538792005    0.030458179653           25
        3          1213793492    0.045792760652           25
        4           882506846    0.030886124038           25
        5           110835222    0.034514389077           25
        6           811074617    0.031775041304           25
        7           148473773    0.034890683708           25
        8           355705195    0.029603835701           25
        9           959893356    0.039487060531           25
       10           518239176     0.02952746213           25
       11          1226430745    0.032546776975           25
       12            81185031    0.068975139607           25
       13           870634041    0.038049176385           25
       14          1883108708    0.033989290043           25
       15          1582903731    0.029665365249           25
       16          1970320493      0.0324530858           25
       17          1284525017    0.032887291336           25
       18            81361273    0.037703206522           25
       19          1722390752    0.038430606365           25
       20          1631262365    0.033811034018           25
       21           220466890    0.033661918057           25
       22             2102062    0.048517000067           25
       23          1729702870    0.043992935838           25
       24          1429021620    0.029961172895           25
       25          1158270622     0.02701002041           25
       26           411379784    0.030926791372           25
       27           555603309    0.036143848779           25
       28          1173765426    0.029602446998           25
       29          1122951988    0.027934219267           25
       30           583036664     0.03060139632           25
       31          1902128312    0.035291117592           25
       32           412596234    0.031002837286           25
 
 
 
 
Search # 2 FUNNEL LAYERS trial # 2 : LOGISTIC : Training
 
_ITER_     _AIC_      _AVERR_        _MISC_    _VAVERR_     _VMISC_
 
   0      1074.24    0.027010    .008424600     0.24123    0.049116
   1      1073.78    0.026913    .007160910     0.24104    0.049116
   2      1072.72    0.026689    .008003370     0.24259    0.049116
   3      1072.43    0.026628    .007160910     0.24271    0.048134
   4      1071.29    0.026388    .008003370     0.24205    0.048134
   5      1070.42    0.026204    .007582140     0.23967    0.049116
   6      1069.59    0.026029    .007160910     0.23916    0.049116
   7      1068.84    0.025872    .007160910     0.24014    0.050098
   8      1067.86    0.025667    .006739680     0.23902    0.049116
   9      1066.83    0.025448    .007160910     0.23996    0.047151
  10      1066.17    0.025309    .006318450     0.23960    0.047151
  11      1065.13    0.025091    .007160910     0.23883    0.046169
  12      1064.54    0.024966    .006318450     0.23807    0.045187
  13      1063.78    0.024807    .005897220     0.23818    0.046169
  14      1063.05    0.024653    .007160910     0.23978    0.049116
  15      1062.24    0.024482    .006318450     0.23938    0.048134
  16      1061.84    0.024397    .006318450     0.24016    0.048134
  17      1061.20    0.024264    .005897220     0.24049    0.048134
  18      1060.46    0.024106    .006318450     0.24189    0.049116
  19      1059.44    0.023893    .005897220     0.24330    0.047151
  20      1058.92    0.023783    .005054760     0.24785    0.051081
  21      1058.11    0.023611    .005475990     0.24625    0.049116
  22      1056.89    0.023355    .005475990     0.24649    0.051081
  23      1055.98    0.023164    .005475990     0.25348    0.053045
  24      1055.17    0.022993    .005054760     0.24859    0.053045
  25      1054.26    0.022801    .004212300     0.25173    0.054028
  26      1053.92    0.022730    .005054760     0.24671    0.052063
  27      1053.27    0.022593    .004633530     0.25106    0.054028
  28      1053.10    0.022556    .005054760     0.24697    0.052063
  29      1052.33    0.022394    .005054760     0.25123    0.055010
  30      1051.71    0.022265    .004633530     0.24806    0.053045
  31      1050.83    0.022079    .005054760     0.25160    0.050098
  32      1049.76    0.021853    .005054760     0.25163    0.049116
  33      1049.46    0.021791    .005475990     0.25220    0.051081
  34      1048.53    0.021595    .005054760     0.25174    0.049116
  35      1047.52    0.021381    .005475990     0.25189    0.049116
  36      1046.67    0.021202    .005054760     0.24891    0.051081
  37      1045.75    0.021009    .005897220     0.25160    0.050098
  38      1045.07    0.020867    .005897220     0.24741    0.047151
  39      1044.14    0.020670    .005475990     0.24924    0.048134
  40      1043.02    0.020434    .005475990     0.24855    0.047151
  41      1042.32    0.020286    .005475990     0.24486    0.046169
  42      1041.45    0.020103    .005897220     0.24322    0.047151
  43      1040.50    0.019903    .005897220     0.24432    0.046169
  44      1040.01    0.019800    .005897220     0.24061    0.044204
  45      1039.29    0.019648    .005897220     0.24072    0.044204
  46      1039.06    0.019599    .005897220     0.24255    0.046169
  47      1038.18    0.019414    .005897220     0.23990    0.044204
  48      1037.29    0.019227    .006318450     0.23918    0.045187
  49      1036.93    0.019152    .005475990     0.23842    0.044204
  50      1035.96    0.018946    .005897220     0.23943    0.043222
  50      1035.96    0.018946    .005897220     0.23943    0.043222
 
 
 
 
Selected Iteration based on _VMISC_
 
_ITER_     _AIC_      _AVERR_        _MISC_    _VAVERR_     _VMISC_
 
  50      1035.96    0.018946    .005897220     0.23943    0.043222
 
 
 
 
Search # 2 FUNNEL LAYERS trial # 3 : SINE : Prelim
 
The NEURAL Procedure
 
Preliminary       Starting         Objective         Number
 Training          Random           Function           of        Terminating
    Run             Seed             Value         Iterations     Criteria
 
        1           597562455    0.037416548258           25
        2          1538792005      0.0246469141           25
        3          1213793492    0.031822745198           25
        4           882506846    0.030003787362           25
        5           110835222    0.027575908352           25
        6           811074617    0.023114865827           25
        7           148473773    0.032413692187           25
        8           355705195    0.027468944527           25
        9           959893356    0.026807391784           25
       10           518239176    0.026894427727           25
       11          1226430745    0.029835626259           25
       12            81185031    0.032569342152           25
       13           870634041    0.029406047135           25
       14          1883108708    0.032858951367           25
       15          1582903731    0.023823268404           25
       16          1970320493    0.037209091835           25
       17          1284525017    0.024917906875           25
       18            81361273    0.040397088539           25
       19          1722390752    0.029435555487           25
       20          1631262365    0.059958573901           25
       21           220466890    0.029412741803           25
       22             2102062    0.036989257707           25
       23          1729702870    0.043265175099           25
       24          1429021620    0.026394830332           25
       25          1158270622    0.028592209609           25
       26           411379784    0.029210507153           25
       27           555603309    0.027387895795           25
       28          1173765426    0.026176410607           25
       29          1122951988    0.022306431155           25
       30           583036664    0.026066813818           25
       31          1902128312    0.030523087804           25
       32           412596234    0.028452375564           25
 
 
 
 
Search # 2 FUNNEL LAYERS trial # 3 : SINE : Training
 
_ITER_     _AIC_      _AVERR_        _MISC_    _VAVERR_     _VMISC_
 
   0      1051.91    0.022306    .006739680     0.37824    0.055992
   1      1050.49    0.022007    .006739680     0.37876    0.057957
   2      1049.52    0.021804    .006318450     0.37831    0.057957
   3      1048.78    0.021647    .006739680     0.37775    0.056974
   4      1048.25    0.021535    .005897220     0.37758    0.057957
   5      1046.88    0.021247    .006318450     0.37658    0.057957
   6      1046.38    0.021142    .006318450     0.37617    0.057957
   7      1045.68    0.020994    .005475990     0.37626    0.057957
   8      1045.20    0.020894    .005897220     0.37525    0.057957
   9      1044.84    0.020817    .005897220     0.37306    0.056974
  10      1044.29    0.020701    .005897220     0.37304    0.056974
  11      1043.80    0.020599    .006318450     0.36993    0.055992
  12      1043.59    0.020553    .006318450     0.37094    0.055992
  13      1042.56    0.020338    .005897220     0.37058    0.055992
  14      1041.91    0.020201    .005475990     0.37037    0.055992
  15      1041.70    0.020155    .006318450     0.37208    0.055992
  16      1040.52    0.019908    .006739680     0.37174    0.055992
  17      1040.30    0.019862    .006739680     0.37018    0.055992
  18      1039.04    0.019596    .005897220     0.37397    0.054028
  19      1038.50    0.019483    .005475990     0.37395    0.054028
  20      1038.25    0.019430    .005054760     0.37414    0.054028
  21      1037.64    0.019302    .005054760     0.37413    0.054028
  22      1037.25    0.019218    .005054760     0.37466    0.053045
  23      1037.07    0.019180    .005054760     0.37580    0.052063
  24      1036.03    0.018963    .004212300     0.37403    0.053045
  25      1034.86    0.018715    .004212300     0.37531    0.051081
  26      1034.70    0.018681    .004212300     0.37437    0.051081
  27      1033.77    0.018486    .003791070     0.37765    0.051081
  28      1032.52    0.018223    .003791070     0.37734    0.050098
  29      1032.31    0.018179    .003791070     0.37765    0.050098
  30      1031.77    0.018064    .003791070     0.37814    0.051081
  31      1030.98    0.017898    .003791070     0.37724    0.052063
  32      1030.79    0.017857    .003369840     0.37816    0.051081
  33      1030.53    0.017803    .003791070     0.37938    0.051081
  34      1029.06    0.017495    .004212300     0.38283    0.053045
  35      1028.25    0.017323    .004212300     0.38267    0.051081
  36      1028.01    0.017271    .004212300     0.38332    0.051081
  37      1026.92    0.017043    .003369840     0.38626    0.052063
  38      1025.10    0.016660    .002948610     0.38558    0.049116
  39      1024.29    0.016488    .003369840     0.38765    0.050098
  40      1024.10    0.016449    .003369840     0.38772    0.050098
  41      1023.77    0.016379    .002948610     0.38885    0.049116
  42      1022.63    0.016139    .002948610     0.39570    0.051081
  43      1021.38    0.015877    .003369840     0.39543    0.050098
  44      1021.17    0.015832    .002948610     0.39750    0.050098
  45      1020.85    0.015765    .002948610     0.39994    0.052063
  46      1019.51    0.015482    .002527380     0.40635    0.053045
  47      1019.17    0.015411    .003369840     0.40067    0.052063
  48      1018.39    0.015246    .002948610     0.40224    0.052063
  49      1018.27    0.015222    .002948610     0.40386    0.053045
  50      1018.08    0.015182    .003369840     0.40520    0.053045
  50      1018.08    0.015182    .003369840     0.40520    0.053045
 
 
 
 
Selected Iteration based on _VMISC_
 
_ITER_     _AIC_      _AVERR_        _MISC_    _VAVERR_     _VMISC_
 
  38      1025.10    0.016660    .002948610     0.38558    0.049116
 
 
 
 
Search # 2 FUNNEL LAYERS trial # 4 : SOFTMAX : Prelim
 
The NEURAL Procedure
 
Preliminary       Starting         Objective         Number
 Training          Random           Function           of        Terminating
    Run             Seed             Value         Iterations     Criteria
 
        1           604901746    0.057331421696           25
        2           796374574    0.037008349465           25
        3          1832822569    0.037806313944           25
        4          1501007047    0.030120744859           25
        5           554418248    0.034479908807           25
        6          1350652522    0.046451691499           25
        7           547243750    0.035133565242           25
        8            93168191    0.049485877175           25
        9            69622871    0.038516636619           25
       10          1565665753    0.033392976204           25
       11          1209834361    0.036696863228           25
       12          2116035701    0.037625860376           25
       13           217752716    0.031632507095           25
       14           280112036    0.048547712248           25
       15          1759817717    0.040994538585           25
       16          1587724599    0.048383943403           25
       17           205739322    0.039499785347           25
       18           958935477    0.039466886024           25
       19            81361273    0.033581706395           25
       20          1522031065    0.031067794201           25
       21          2079526044    0.042098762824           25
       22          1268519954    0.028334184121           25
       23          1297447711    0.066730144632           25
       24          2097659896    0.031877178334           25
       25           936300451    0.029636242345           25
       26           997087842    0.040435133844           25
       27           352289250    0.048476759094           25
       28           246747632    0.040203338429           25
       29          1961462567    0.052945653379           25
       30          1794803742    0.062259338374           25
       31          1409408970    0.033917016291           25
       32          1899343126    0.032471515744           25
 
 
 
 
Search # 2 FUNNEL LAYERS trial # 4 : SOFTMAX : Training
 
_ITER_     _AIC_      _AVERR_        _MISC_    _VAVERR_     _VMISC_
 
   0      1050.53    0.028334    .008424600     0.23431    0.056974
   1      1049.13    0.028039    .007160910     0.23503    0.054028
   2      1048.58    0.027923    .007582140     0.23545    0.053045
   3      1046.03    0.027387    .007160910     0.23650    0.052063
   4      1044.26    0.027013    .006318450     0.23663    0.052063
   5      1042.67    0.026678    .006739680     0.23492    0.054028
   6      1040.41    0.026202    .006318450     0.23746    0.053045
   7      1038.43    0.025786    .005475990     0.24087    0.057957
   8      1036.57    0.025393    .005475990     0.23985    0.057957
   9      1035.68    0.025206    .004212300     0.24350    0.057957
  10      1034.39    0.024935    .004633530     0.24165    0.056974
  11      1032.91    0.024624    .005475990     0.23963    0.055010
  12      1031.69    0.024367    .005054760     0.24137    0.053045
  13      1031.17    0.024257    .004633530     0.23865    0.052063
  14      1029.74    0.023956    .004633530     0.24053    0.052063
  15      1026.76    0.023328    .004633530     0.24174    0.050098
  16      1025.56    0.023074    .003791070     0.24050    0.050098
  17      1023.07    0.022550    .003791070     0.24481    0.046169
  18      1021.74    0.022269    .003791070     0.24405    0.048134
  19      1020.79    0.022070    .003369840     0.24821    0.047151
  20      1019.58    0.021815    .003369840     0.24727    0.046169
  21      1017.75    0.021429    .002948610     0.24832    0.045187
  22      1016.80    0.021230    .002948610     0.25190    0.043222
  23      1015.49    0.020953    .002948610     0.25478    0.045187
  24      1013.78    0.020594    .003791070     0.25738    0.045187
  25      1012.51    0.020326    .004212300     0.26042    0.048134
  26      1010.67    0.019938    .003791070     0.26041    0.047151
  27      1008.49    0.019479    .003791070     0.26835    0.046169
  28      1006.77    0.019118    .003369840     0.26658    0.047151
  29      1004.60    0.018660    .002948610     0.27221    0.048134
  30      1003.01    0.018325    .003369840     0.27671    0.050098
  31      1001.20    0.017945    .003791070     0.27872    0.049116
  32      1000.19    0.017731    .003791070     0.27591    0.049116
  33       999.46    0.017578    .003791070     0.28245    0.050098
  34       998.45    0.017364    .003369840     0.28032    0.049116
  35       996.93    0.017045    .003369840     0.28218    0.049116
  36       995.81    0.016809    .002948610     0.28305    0.051081
  37       995.30    0.016701    .003369840     0.28526    0.051081
  38       993.92    0.016411    .003369840     0.28531    0.052063
  39       992.44    0.016099    .002527380     0.29365    0.050098
  40       991.55    0.015912    .002948610     0.29565    0.049116
  41       990.53    0.015696    .002527380     0.29380    0.051081
  42       989.45    0.015469    .002527380     0.30087    0.051081
  43       988.14    0.015193    .002527380     0.29978    0.052063
  44       987.23    0.015002    .002527380     0.30305    0.053045
  45       986.44    0.014835    .002527380     0.30532    0.053045
  46       986.17    0.014778    .002527380     0.30579    0.054028
  47       985.30    0.014596    .002106150     0.30650    0.055010
  48       984.43    0.014412    .002527380     0.31058    0.053045
  49       983.47    0.014211    .002527380     0.30884    0.053045
  50       982.96    0.014102    .002527380     0.30786    0.053045
  50       982.96    0.014102    .002527380     0.30786    0.053045
 
 
 
 
Selected Iteration based on _VMISC_
 
_ITER_     _AIC_      _AVERR_        _MISC_    _VAVERR_     _VMISC_
 
  22      1016.80    0.021230    .002948610     0.25190    0.043222
 
 
 
 
Final Training Prelim
 
The NEURAL Procedure
 
Preliminary       Starting         Objective         Number
 Training          Random           Function           of        Terminating
    Run             Seed             Value         Iterations     Criteria
 
        1               12345    0.030832606414           25
 
 
 
 
Final Training Training
 
_ITER_     _AIC_      _AVERR_        _MISC_    _VAVERR_     _VMISC_
 
   0      522.393    0.030833    .009267060     0.27035    0.051081
   1      521.974    0.030744    .008424600     0.27031    0.052063
   2      521.447    0.030633    .008845830     0.26910    0.051081
   3      521.203    0.030582    .008424600     0.26874    0.049116
   4      520.793    0.030496    .008003370     0.26953    0.051081
   5      520.078    0.030345    .008003370     0.27061    0.050098
   5      520.078    0.030345    .008003370     0.27061    0.050098
 
 
 
 
Selected Iteration based on _VMISC_
 
_ITER_     _AIC_      _AVERR_        _MISC_    _VAVERR_     _VMISC_
 
   3      521.203    0.030582    .008424600     0.26874    0.049116
 
 
 
 
Final Training History
 
                             _                                   _
                             s           _                       V       _
       _           _         t      _    A       _               A       V
       s           f         a      i    V       M       _       V       M
       t           u         t      t    E       I       A       E       I
       e           n         u      e    R       S       I       R       S
       p           c         s      r    R       C       C       R       C
       _           _         _      _    _       _       _       _       _
 
FUNNEL LAYERS 1 DIRECT   initial    0 0.42482 0.15122 2077.06 0.42661 0.15226
FUNNEL LAYERS 1 DIRECT   candidate  6 0.14238 0.05897  736.00 0.15075 0.06680
FUNNEL LAYERS 1 LOGISTIC candidate  7 0.03981 0.01222  625.04 0.20167 0.05403
FUNNEL LAYERS 1 SINE     candidate 22 0.05060 0.01601  676.24 0.12265 0.04617
FUNNEL LAYERS 1 SOFTMAX  candidate 15 0.04017 0.01348  566.72 0.20847 0.04224
FUNNEL LAYERS 1 SOFTMAX  keep      15 0.04017 0.01348  566.72 0.20847 0.04224
FUNNEL LAYERS 2 DIRECT   reject    41 0.02296 0.00548  543.02 0.29907 0.04519
FUNNEL LAYERS 2 LOGISTIC reject    50 0.01895 0.00590 1035.96 0.23943 0.04322
FUNNEL LAYERS 2 SINE     reject    38 0.01666 0.00295 1025.10 0.38558 0.04912
FUNNEL LAYERS 2 SOFTMAX  reject    22 0.02123 0.00295 1016.80 0.25190 0.04322
                         Final      3 0.03058 0.00842  521.20 0.26874 0.04912
 
 
 
 
Final Model
Stopping: Termination criteria were satisfied: overfitting based on _VMISC_
 
_func_      _AVERR_    _VAVERR_    neurons
 
SOFTMAX    0.040168     0.20847       7
                                   =======
                                      7


*------------------------------------------------------------*
* Score Output
*------------------------------------------------------------*


*------------------------------------------------------------*
* Report Output
*------------------------------------------------------------*
 
 
 
 
Fit Statistics
 
Target=DepVar Target Label=DepVar
 
   Fit
Statistics    Statistics Label                     Train    Validation
 
 _DFT_        Total Degrees of Freedom           2374.00          .
 _DFE_        Degrees of Freedom for Error       2186.00          .
 _DFM_        Model Degrees of Freedom            188.00          .
 _NW_         Number of Estimated Weights         188.00          .
 _AIC_        Akaike's Information Criterion      521.20          .
 _SBC_        Schwarz's Bayesian Criterion       1606.40          .
 _ASE_        Average Squared Error                 0.01         0.04
 _MAX_        Maximum Absolute Error                1.00         1.00
 _DIV_        Divisor for ASE                    4748.00      2036.00
 _NOBS_       Sum of Frequencies                 2374.00      1018.00
 _RASE_       Root Average Squared Error            0.09         0.20
 _SSE_        Sum of Squared Errors                36.59        85.24
 _SUMW_       Sum of Case Weights Times Freq     4748.00      2036.00
 _FPE_        Final Prediction Error                0.01          .
 _MSE_        Mean Squared Error                    0.01         0.04
 _RFPE_       Root Final Prediction Error           0.10          .
 _RMSE_       Root Mean Squared Error               0.09         0.20
 _AVERR_      Average Error Function                0.03         0.27
 _ERR_        Error Function                      145.20       547.15
 _MISC_       Misclassification Rate                0.01         0.05
 _WRONG_      Number of Wrong Classifications      20.00        50.00
 
 
 
 
Classification Table
 
Data Role=TRAIN Target Variable=DepVar Target Label=DepVar
 
                       Target        Outcome     Frequency       Total
Target    Outcome    Percentage    Percentage      Count      Percentage
 
  0          0         99.2593       99.7519        2010        84.6672
  1          0          0.7407        4.1783          15         0.6318
  0          1          1.4327        0.2481           5         0.2106
  1          1         98.5673       95.8217         344        14.4903
 
 
Data Role=VALIDATE Target Variable=DepVar Target Label=DepVar
 
                       Target        Outcome     Frequency       Total
Target    Outcome    Percentage    Percentage      Count      Percentage
 
  0          0         97.1031       97.1031        838         82.3183
  1          0          2.8969       16.1290         25          2.4558
  0          1         16.1290        2.8969         25          2.4558
  1          1         83.8710       83.8710        130         12.7701
 
 
 
 
Event Classification Table
 
Data Role=TRAIN Target=DepVar Target Label=DepVar
 
  False       True        False       True
Negative    Negative    Positive    Positive
 
   15         2010          5          344
 
 
Data Role=VALIDATE Target=DepVar Target Label=DepVar
 
  False       True        False       True
Negative    Negative    Positive    Positive
 
   25          838         25          130
 
 
 
 
Assessment Score Rankings
 
Data Role=TRAIN Target Variable=DepVar Target Label=DepVar
 
                                                                                    Mean
                            Cumulative       %      Cumulative     Number of     Posterior
Depth      Gain     Lift       Lift      Response   % Response   Observations   Probability
 
   5    561.281   6.61281     6.61281     100.000     100.000         119         1.00000
  10    561.281   6.61281     6.61281     100.000     100.000         119         0.99988
  15    542.758   6.05711     6.42758      91.597      97.199         119         0.84190
  20    395.613   0.50437     4.95613       7.627      74.947         118         0.15691
  25    298.550   0.11114     3.98550       1.681      60.269         119         0.01654
  30    232.959   0.05557     3.32959       0.840      50.351         119         0.00304
  35    185.680   0.00000     2.85680       0.000      43.201         118         0.00112
  40    149.895   0.00000     2.49895       0.000      37.789         119         0.00050
  45    122.077   0.00000     2.22077       0.000      33.583         119         0.00021
  50    100.000   0.00000     2.00000       0.000      30.244         118         0.00009
  55     81.776   0.00000     1.81776       0.000      27.489         119         0.00003
  60     66.596   0.00000     1.66596       0.000      25.193         119         0.00001
  65     53.756   0.00000     1.53756       0.000      23.251         119         0.00000
  70     42.840   0.00000     1.42840       0.000      21.600         118         0.00000
  75     33.296   0.00000     1.33296       0.000      20.157         119         0.00000
  80     24.947   0.00000     1.24947       0.000      18.895         119         0.00000
  85     17.641   0.00000     1.17641       0.000      17.790         118         0.00000
  90     11.090   0.00000     1.11090       0.000      16.799         119         0.00000
  95      5.230   0.00000     1.05230       0.000      15.913         119         0.00000
 100      0.000   0.00000     1.00000       0.000      15.122         118         0.00000
 
 
Data Role=VALIDATE Target Variable=DepVar Target Label=DepVar
 
                                                                                    Mean
                            Cumulative       %      Cumulative     Number of     Posterior
Depth      Gain     Lift       Lift      Response   % Response   Observations   Probability
 
   5    543.896   6.43896     6.43896     98.0392     98.0392         51          1.00000
  10    518.140   5.92385     6.18140     90.1961     94.1176         51          0.99975
  15    453.751   4.24972     5.53751     64.7059     84.3137         51          0.82750
  20    347.508   1.28779     4.47508     19.6078     68.1373         51          0.20333
  25    265.733   0.38634     3.65733      5.8824     55.6863         51          0.01404
  30    213.363   0.51512     3.13363      7.8431     47.7124         51          0.00280
  35    170.436   0.12878     2.70436      1.9608     41.1765         51          0.00089
  40    141.461   0.38634     2.41461      5.8824     36.7647         51          0.00039
  45    117.494   0.25756     2.17494      3.9216     33.1155         51          0.00016
  50     96.129   0.00000     1.96129      0.0000     29.8625         50          0.00006
  55     79.440   0.12878     1.79440      1.9608     27.3214         51          0.00003
  60     65.537   0.12878     1.65537      1.9608     25.2046         51          0.00001
  65     52.784   0.00000     1.52784      0.0000     23.2628         51          0.00000
  70     42.777   0.12878     1.42777      1.9608     21.7391         51          0.00000
  75     33.246   0.00000     1.33246      0.0000     20.2880         51          0.00000
  80     24.908   0.00000     1.24908      0.0000     19.0184         51          0.00000
  85     17.552   0.00000     1.17552      0.0000     17.8984         51          0.00000
  90     11.014   0.00000     1.11014      0.0000     16.9029         51          0.00000
  95      5.165   0.00000     1.05165      0.0000     16.0124         51          0.00000
 100      0.000   0.00000     1.00000      0.0000     15.2259         50          0.00000
 
 
 
 
Assessment Score Distribution
 
Data Role=TRAIN Target Variable=DepVar Target Label=DepVar
 
 Posterior     Number                     Mean
Probability      of      Number of     Posterior
   Range       Events    Nonevents    Probability    Percentage
 
 0.95-1.00       286           0        0.99683        12.0472
 0.90-0.95        13           0        0.92576         0.5476
 0.85-0.90        13           0        0.87559         0.5476
 0.80-0.85        10           0        0.81545         0.4212
 0.75-0.80         5           0        0.77554         0.2106
 0.70-0.75         6           0        0.72284         0.2527
 0.65-0.70         3           2        0.66984         0.2106
 0.60-0.65         4           0        0.63345         0.1685
 0.55-0.60         1           1        0.56901         0.0842
 0.50-0.55         3           2        0.53296         0.2106
 0.45-0.50         1           2        0.46906         0.1264
 0.40-0.45         3           6        0.42961         0.3791
 0.35-0.40         0           2        0.37894         0.0842
 0.30-0.35         3           5        0.32483         0.3370
 0.25-0.30         1           6        0.27420         0.2949
 0.20-0.25         1          12        0.22767         0.5476
 0.15-0.20         1          15        0.16632         0.6740
 0.10-0.15         0          23        0.12084         0.9688
 0.05-0.10         2          34        0.07667         1.5164
 0.00-0.05         3        1905        0.00156        80.3707
 
 
Data Role=VALIDATE Target Variable=DepVar Target Label=DepVar
 
 Posterior     Number                     Mean
Probability      of      Number of     Posterior
   Range       Events    Nonevents    Probability    Percentage
 
 0.95-1.00       106         12         0.99688        11.5914
 0.90-0.95         4          1         0.92360         0.4912
 0.85-0.90         4          1         0.87304         0.4912
 0.80-0.85         1          2         0.82789         0.2947
 0.75-0.80         6          2         0.77608         0.7859
 0.70-0.75         3          0         0.72157         0.2947
 0.65-0.70         2          2         0.67048         0.3929
 0.60-0.65         1          1         0.61601         0.1965
 0.55-0.60         2          2         0.56569         0.3929
 0.50-0.55         1          2         0.53777         0.2947
 0.45-0.50         1          4         0.47770         0.4912
 0.40-0.45         2          2         0.43120         0.3929
 0.30-0.35         0          1         0.32897         0.0982
 0.25-0.30         3          1         0.26680         0.3929
 0.20-0.25         1          3         0.23595         0.3929
 0.15-0.20         1          4         0.17819         0.4912
 0.10-0.15         0          9         0.11981         0.8841
 0.05-0.10         1          6         0.06611         0.6876
 0.00-0.05        16        808         0.00164        80.9430
