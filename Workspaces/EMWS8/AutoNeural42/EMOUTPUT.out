*------------------------------------------------------------*
User:                Lukas Fahr
Date:                28. April 2016
Time:                19.40 Uhr
*------------------------------------------------------------*
* Training Output
*------------------------------------------------------------*
 
 
 
 
Variable Summary
 
            Measurement    Frequency
Role           Level         Count
 
INPUT        INTERVAL          13
INPUT        NOMINAL            1
REJECTED     BINARY             7
REJECTED     INTERVAL          11
REJECTED     NOMINAL            1
TARGET       BINARY             1
 
 
 
 
Model Events
 
                                  Number
                   Measurement      of
Target    Event       Level       Levels      Order       Label
 
DepVar      1        BINARY          2      Descending    DepVar
 
 
 
 
Predicted and decision variables
 
Type         Variable     Label
 
TARGET       DepVar       DepVar
PREDICTED    P_DepVar1    Predicted: DepVar=1
RESIDUAL     R_DepVar1    Residual: DepVar=1
PREDICTED    P_DepVar0    Predicted: DepVar=0
RESIDUAL     R_DepVar0    Residual: DepVar=0
FROM         F_DepVar     From: DepVar
INTO         I_DepVar     Into: DepVar
 
 
 
 
Search # 1 FUNNEL LAYERS trial # 1 : DIRECT : Training
 
_ITER_     _AIC_     _AVERR_     _MISC_    _VAVERR_    _VMISC_
 
   0      2053.06    0.42482    0.15122     0.42661    0.15226
   1       922.46    0.18670    0.06276     0.19902    0.06778
   2       726.99    0.14553    0.05981     0.15231    0.07171
   3       715.08    0.14303    0.05939     0.14883    0.07269
   4       714.68    0.14294    0.05813     0.14915    0.07171
   5       714.36    0.14287    0.05939     0.14883    0.07073
   6       714.29    0.14286    0.05813     0.14895    0.07171
   7       714.25    0.14285    0.05939     0.14886    0.07073
   8       714.23    0.14285    0.05897     0.14890    0.07171
   9       714.23    0.14284    0.05939     0.14887    0.07073
  10       714.23    0.14284    0.05939     0.14889    0.07073
  11       714.22    0.14284    0.05939     0.14888    0.07073
  12       714.22    0.14284    0.05939     0.14889    0.07073
  13       714.22    0.14284    0.05939     0.14888    0.07073
  14       714.22    0.14284    0.05939     0.14889    0.07073
  14       714.22    0.14284    0.05939     0.14889    0.07073
 
 
 
 
Selected Iteration based on _VMISC_
 
_ITER_     _AIC_     _AVERR_     _MISC_     _VAVERR_     _VMISC_
 
   1      922.463    0.18670    0.062763     0.19902    0.067780
 
 
 
 
Search # 1 FUNNEL LAYERS trial # 2 : LOGISTIC : Prelim
 
The NEURAL Procedure
 
Preliminary       Starting         Objective         Number
 Training          Random           Function           of        Terminating
    Run             Seed             Value         Iterations     Criteria
 
        1           679865644    0.089736670594           25
        2           335245709     0.08996921894           25
        3           466641608    0.082612209456           25
        4          2007033381    0.090041480577           25
        5           796374574     0.09166072441           25
        6           244017995    0.096469162846           25
        7          1968674623    0.091367157975           25
        8          2059748735    0.073570413944           25
        9           777001991    0.102668575796           25
       10          1501007047    0.103977037679           25
       11          2038899368    0.075524295617           25
       12           286121952    0.083989618677           25
       13           519817022    0.111401530573           25
       14          1009867108    0.078711674196           25
       15          1350652522    0.088968214517           25
       16           531622452    0.085022339132           25
       17           739710244    0.095455090274           25
       18          1174413546    0.074722148096           25
       19           838431652    0.080808153834           25
       20            93168191    0.081840616303           25
       21           523856897    0.100532027381           25
       22           983313733    0.101086247979           25
       23          1756616176    0.094806038422           25
       24          1422700854    0.078094366609           25
 
 
 
 
Search # 1 FUNNEL LAYERS trial # 2 : LOGISTIC : Training
 
_ITER_     _AIC_      _AVERR_     _MISC_     _VAVERR_     _VMISC_
 
   0      579.312    0.073570    0.029065     0.13117    0.052063
   1      576.483    0.072975    0.026116     0.12977    0.050098
   2      571.505    0.071926    0.027380     0.12869    0.054028
   3      567.211    0.071022    0.026116     0.13100    0.053045
   4      565.754    0.070715    0.024431     0.13030    0.053045
   5      564.726    0.070498    0.024431     0.12982    0.053045
   6      562.983    0.070131    0.024431     0.12887    0.053045
   7      560.954    0.069704    0.026537     0.12744    0.052063
   8      559.538    0.069406    0.026116     0.12755    0.054028
   9      557.753    0.069030    0.023168     0.12681    0.051081
  10      554.033    0.068246    0.025695     0.12459    0.051081
  11      551.736    0.067762    0.025274     0.12526    0.052063
  12      545.922    0.066538    0.025695     0.12593    0.054028
  13      542.617    0.065842    0.025695     0.12404    0.055992
  14      538.670    0.065011    0.028644     0.12217    0.052063
  15      534.565    0.064146    0.026116     0.11950    0.054028
  16      532.029    0.063612    0.025695     0.12097    0.054028
  17      528.829    0.062938    0.025695     0.12152    0.055992
  18      524.993    0.062130    0.024431     0.12442    0.055992
  19      523.839    0.061887    0.024431     0.13095    0.058939
  20      520.991    0.061287    0.024431     0.12657    0.056974
  21      516.925    0.060431    0.023168     0.12726    0.052063
  22      515.002    0.060026    0.021483     0.13081    0.055010
  23      512.155    0.059426    0.023168     0.12771    0.054028
  24      510.386    0.059053    0.021904     0.12600    0.054028
  25      508.413    0.058638    0.022746     0.12626    0.055010
  26      506.026    0.058135    0.020640     0.12667    0.051081
  27      502.761    0.057448    0.020640     0.12537    0.054028
  28      499.176    0.056693    0.021483     0.12916    0.054028
  29      494.442    0.055696    0.017692     0.12759    0.055992
  30      491.114    0.054994    0.017692     0.13220    0.055010
  31      488.976    0.054544    0.019377     0.13373    0.056974
  32      486.589    0.054042    0.020219     0.13639    0.055992
  33      484.894    0.053685    0.019377     0.13814    0.056974
  34      482.692    0.053221    0.019798     0.13701    0.056974
  35      479.935    0.052640    0.019798     0.13780    0.055010
  36      478.494    0.052337    0.019798     0.13789    0.053045
  37      475.436    0.051692    0.022325     0.13785    0.054028
  38      472.407    0.051055    0.018534     0.14001    0.052063
  39      470.691    0.050693    0.019798     0.13887    0.055010
  40      468.312    0.050192    0.019798     0.14112    0.054028
  41      466.162    0.049739    0.018534     0.14181    0.054028
  42      463.631    0.049206    0.019377     0.14309    0.052063
  43      461.427    0.048742    0.018534     0.13975    0.050098
  44      459.263    0.048286    0.017270     0.14546    0.052063
  45      456.496    0.047703    0.017270     0.14233    0.050098
  46      454.483    0.047280    0.018534     0.14944    0.052063
  47      453.263    0.047023    0.017270     0.14858    0.051081
  48      451.751    0.046704    0.017692     0.15040    0.051081
  49      447.463    0.045801    0.016428     0.16131    0.052063
  50      445.272    0.045339    0.016007     0.15642    0.053045
  50      445.272    0.045339    0.016007     0.15642    0.053045
 
 
 
 
Selected Iteration based on _VMISC_
 
_ITER_     _AIC_      _AVERR_     _MISC_     _VAVERR_     _VMISC_
 
   1      576.483    0.072975    0.026116     0.12977    0.050098
 
 
 
 
Search # 1 FUNNEL LAYERS trial # 3 : SINE : Prelim
 
The NEURAL Procedure
 
Preliminary       Starting         Objective         Number
 Training          Random           Function           of        Terminating
    Run             Seed             Value         Iterations     Criteria
 
        1           679865644    0.102736435577           25
        2           335245709    0.084825449916           25
        3           466641608    0.092243188741           25
        4          2007033381    0.100865544667           25
        5           796374574    0.090193604094           25
        6           244017995    0.090776694019           25
        7          1968674623    0.103444956029           25
        8          2059748735    0.089493022649           25
        9           777001991    0.091541937679           25
       10          1501007047    0.103623895953           25
       11          2038899368    0.092159416726           25
       12           286121952    0.086319785668           25
       13           519817022    0.079956523136           25
       14          1009867108     0.08626800611           25
       15          1350652522    0.088090502237           25
       16           531622452    0.090839015331           25
       17           739710244    0.093109261484           25
       18          1174413546    0.084696234888           25
       19           838431652    0.085676181672           25
       20            93168191     0.08610543911           25
       21           523856897    0.103018970219           25
       22           983313733    0.085249089309           25
       23          1756616176    0.093185561353           25
       24          1422700854    0.084293439778           25
 
 
 
 
Search # 1 FUNNEL LAYERS trial # 3 : SINE : Training
 
_ITER_     _AIC_      _AVERR_     _MISC_     _VAVERR_     _VMISC_
 
   0      609.634    0.079957    0.030750     0.14422    0.067780
   1      601.758    0.078298    0.029486     0.13708    0.065815
   2      600.274    0.077985    0.029065     0.13717    0.066798
   3      598.757    0.077666    0.030750     0.13626    0.066798
   4      596.574    0.077206    0.031171     0.13632    0.066798
   5      593.506    0.076560    0.030750     0.13235    0.065815
   6      591.393    0.076115    0.031171     0.13204    0.067780
   7      587.822    0.075363    0.031171     0.13058    0.064833
   8      584.250    0.074610    0.030329     0.12674    0.062868
   9      580.683    0.073859    0.027801     0.12797    0.064833
  10      577.016    0.073087    0.029486     0.12319    0.065815
  11      574.381    0.072532    0.029065     0.12344    0.061886
  12      571.626    0.071952    0.029065     0.12348    0.062868
  13      568.876    0.071372    0.029486     0.12511    0.060904
  14      565.987    0.070764    0.027380     0.13121    0.061886
  15      564.182    0.070384    0.028644     0.13131    0.063851
  16      561.712    0.069863    0.027801     0.12912    0.064833
  17      560.113    0.069527    0.028222     0.13311    0.066798
  18      558.155    0.069114    0.028644     0.13214    0.064833
  19      555.302    0.068513    0.027801     0.13569    0.063851
  20      553.163    0.068063    0.025695     0.12805    0.061886
  21      550.843    0.067574    0.028222     0.12950    0.061886
  22      548.613    0.067105    0.025695     0.12049    0.057957
  23      546.587    0.066678    0.026537     0.11895    0.056974
  24      544.261    0.066188    0.025274     0.12132    0.058939
  25      540.766    0.065452    0.026116     0.12144    0.059921
  26      538.550    0.064985    0.026116     0.12654    0.062868
  27      535.473    0.064337    0.025274     0.12135    0.059921
  28      533.684    0.063960    0.023168     0.12165    0.056974
  29      529.967    0.063177    0.024853     0.12407    0.060904
  30      527.187    0.062592    0.023168     0.12728    0.059921
  31      526.001    0.062342    0.024431     0.12794    0.060904
  32      522.946    0.061699    0.023589     0.12230    0.061886
  33      518.773    0.060820    0.022325     0.12230    0.059921
  34      516.373    0.060314    0.022325     0.12019    0.057957
  35      513.159    0.059637    0.023589     0.11723    0.058939
  36      509.306    0.058826    0.023589     0.11854    0.056974
  37      506.890    0.058317    0.024010     0.11779    0.051081
  38      505.251    0.057972    0.021904     0.12323    0.051081
  39      502.832    0.057463    0.020640     0.12055    0.055010
  40      501.322    0.057144    0.023589     0.11875    0.051081
  41      498.690    0.056590    0.022325     0.11864    0.052063
  42      497.155    0.056267    0.020640     0.12000    0.053045
  43      495.153    0.055845    0.021483     0.11734    0.049116
  44      493.818    0.055564    0.021061     0.11678    0.049116
  45      491.830    0.055145    0.021483     0.11725    0.049116
  46      490.297    0.054823    0.021483     0.11694    0.047151
  47      488.342    0.054411    0.020640     0.11725    0.049116
  48      487.404    0.054213    0.020640     0.12100    0.047151
  49      484.881    0.053682    0.018113     0.11924    0.046169
  50      483.231    0.053334    0.018534     0.11752    0.043222
  50      483.231    0.053334    0.018534     0.11752    0.043222
 
 
 
 
Selected Iteration based on _VMISC_
 
_ITER_     _AIC_      _AVERR_     _MISC_     _VAVERR_     _VMISC_
 
  50      483.231    0.053334    0.018534     0.11752    0.043222
 
 
 
 
Search # 1 FUNNEL LAYERS trial # 4 : SOFTMAX : Prelim
 
The NEURAL Procedure
 
Preliminary       Starting         Objective         Number
 Training          Random           Function           of        Terminating
    Run             Seed             Value         Iterations     Criteria
 
        1          1962974514    0.040762434569           25
        2          1452355784    0.050566254245           25
        3           604901746    0.048158601155           25
        4          1161293754    0.030972139392           25
        5           369857384     0.07102473834           25
        6           796374574    0.046833075399           25
        7          2015235829    0.038577806584           25
        8          1807677195    0.043601297823           25
        9          1832822569    0.084943117789           25
       10           957239873    0.053268267249           25
       11           786049461    0.054788753705           25
       12          1501007047    0.060670271577           25
       13          1527874309     0.03687915678           25
       14          1863809418    0.036052356079           25
       15           554418248    0.040662942132           25
       16          1007790070     0.04310610255           25
       17           538638144    0.082774680837           25
       18          1350652522    0.056727816683           25
       19           811074617    0.037084281093           25
       20           856260411      0.0420254609           25
       21           547243750     0.06198650976           25
       22           688055046    0.014438017935           25
       23           123045530    0.039081073829           25
       24            93168191    0.067870074803           25
 
 
 
 
Search # 1 FUNNEL LAYERS trial # 4 : SOFTMAX : Training
 
_ITER_     _AIC_      _AVERR_        _MISC_    _VAVERR_     _VMISC_
 
   0      262.552    0.014438    .003791070     0.40597    0.045187
   1      260.987    0.014109    .004212300     0.45175    0.047151
   2      260.456    0.013997    .003791070     0.45441    0.047151
   3      260.198    0.013942    .004212300     0.45015    0.047151
   4      260.084    0.013918    .004212300     0.45272    0.046169
   5      260.000    0.013901    .003791070     0.44980    0.046169
   6      259.943    0.013889    .004212300     0.45250    0.046169
   7      259.890    0.013877    .004212300     0.45010    0.046169
   8      259.844    0.013868    .004212300     0.45279    0.046169
   9      259.802    0.013859    .004212300     0.45072    0.046169
  10      259.761    0.013850    .004212300     0.45346    0.047151
  11      259.723    0.013842    .004212300     0.45159    0.047151
  12      259.685    0.013834    .004212300     0.45434    0.047151
  13      259.650    0.013827    .004212300     0.45259    0.047151
  14      259.612    0.013819    .004212300     0.45532    0.048134
  15      259.579    0.013812    .004212300     0.45364    0.047151
  16      259.541    0.013804    .004212300     0.45632    0.048134
  17      259.509    0.013797    .004212300     0.45470    0.048134
  18      259.471    0.013789    .003791070     0.45732    0.047151
  19      259.438    0.013782    .004212300     0.45573    0.047151
  20      259.399    0.013774    .003791070     0.45828    0.047151
  21      259.365    0.013767    .004212300     0.45674    0.047151
  22      259.321    0.013758    .003791070     0.45919    0.046169
  23      259.284    0.013750    .004212300     0.45771    0.047151
  24      259.236    0.013740    .003791070     0.46004    0.045187
  25      259.192    0.013730    .003791070     0.45865    0.045187
  26      259.136    0.013719    .003791070     0.46082    0.045187
  27      259.082    0.013707    .003791070     0.45955    0.045187
  28      259.014    0.013693    .003791070     0.46153    0.044204
  29      258.943    0.013678    .003791070     0.46037    0.043222
  30      258.861    0.013661    .003791070     0.46211    0.044204
  31      258.773    0.013642    .003791070     0.46106    0.042240
  32      258.487    0.013582    .003369840     0.46288    0.041257
  33      257.990    0.013477    .003791070     0.46178    0.042240
  34      257.448    0.013363    .003791070     0.46601    0.043222
  35      256.711    0.013208    .003369840     0.48430    0.044204
  36      256.567    0.013178    .003791070     0.48590    0.043222
  37      256.526    0.013169    .003369840     0.48450    0.043222
  38      256.477    0.013159    .003791070     0.48681    0.043222
  39      256.439    0.013151    .003791070     0.48516    0.043222
  40      256.406    0.013144    .003791070     0.48713    0.043222
  41      256.398    0.013142    .003791070     0.48528    0.044204
  42      256.367    0.013135    .003791070     0.48716    0.044204
  43      256.357    0.013133    .003791070     0.48562    0.044204
  44      256.342    0.013130    .003791070     0.48755    0.044204
  45      256.333    0.013128    .003791070     0.48602    0.044204
  46      256.321    0.013126    .003791070     0.48790    0.045187
  47      256.312    0.013124    .003791070     0.48647    0.044204
  48      256.302    0.013122    .003791070     0.48825    0.045187
  49      256.293    0.013120    .003791070     0.48693    0.044204
  50      256.283    0.013118    .003791070     0.48866    0.045187
  50      256.283    0.013118    .003791070     0.48866    0.045187
 
 
 
 
Selected Iteration based on _VMISC_
 
_ITER_     _AIC_      _AVERR_        _MISC_    _VAVERR_     _VMISC_
 
  32      258.487    0.013582    .003369840     0.46288    0.041257
 
 
 
 
Search # 2 FUNNEL LAYERS trial # 1 : DIRECT : Prelim
 
The NEURAL Procedure
 
Preliminary       Starting         Objective         Number
 Training          Random           Function           of        Terminating
    Run             Seed             Value         Iterations     Criteria
 
        1               12345    0.012763809959           25
 
 
 
 
Search # 2 FUNNEL LAYERS trial # 1 : DIRECT : Training
 
_ITER_     _AIC_      _AVERR_        _MISC_    _VAVERR_     _VMISC_
 
   0      288.603    0.012764    .003791070     0.45984    0.040275
   1      288.438    0.012729    .003791070     0.45918    0.040275
   2      288.412    0.012724    .003791070     0.45902    0.040275
   3      288.370    0.012715    .003791070     0.45907    0.040275
   4      288.306    0.012701    .003791070     0.45928    0.040275
   5      288.212    0.012682    .003791070     0.45927    0.040275
   6      288.147    0.012668    .003791070     0.45971    0.040275
   7      288.079    0.012654    .003791070     0.46005    0.040275
   8      288.007    0.012638    .003791070     0.46021    0.041257
   9      287.913    0.012619    .003791070     0.45966    0.041257
  10      287.854    0.012606    .003791070     0.45953    0.042240
  11      287.808    0.012596    .003791070     0.46071    0.041257
  12      287.746    0.012583    .003791070     0.46046    0.041257
  13      287.703    0.012574    .003791070     0.45982    0.042240
  14      287.611    0.012555    .003791070     0.46049    0.042240
  15      287.546    0.012541    .003791070     0.46082    0.040275
  16      287.391    0.012509    .003791070     0.46077    0.041257
  17      287.139    0.012456    .003791070     0.46101    0.041257
  18      286.805    0.012385    .004212300     0.46329    0.043222
  19      286.241    0.012266    .003791070     0.46448    0.042240
  20      285.411    0.012092    .003791070     0.46719    0.043222
  21      284.896    0.011983    .003369840     0.46557    0.043222
  22      284.351    0.011868    .003791070     0.46632    0.045187
  23      284.143    0.011825    .003369840     0.46631    0.042240
  24      283.715    0.011734    .003791070     0.46709    0.043222
  25      283.442    0.011677    .003791070     0.46836    0.044204
  26      283.137    0.011613    .003791070     0.46838    0.044204
  27      283.005    0.011585    .003791070     0.46723    0.044204
  28      282.786    0.011539    .003791070     0.46706    0.044204
  29      282.449    0.011468    .003791070     0.46617    0.043222
  30      282.085    0.011391    .003791070     0.46566    0.043222
  31      281.884    0.011349    .003791070     0.46580    0.043222
  32      281.780    0.011327    .003791070     0.46696    0.042240
  33      281.601    0.011289    .003791070     0.46613    0.042240
  34      281.413    0.011250    .003369840     0.46409    0.042240
  35      281.166    0.011197    .003791070     0.46413    0.042240
  36      280.921    0.011146    .003791070     0.46258    0.041257
  37      280.859    0.011133    .004212300     0.46156    0.041257
  38      280.653    0.011090    .003791070     0.46265    0.041257
  39      280.557    0.011069    .003791070     0.46120    0.040275
  40      280.320    0.011019    .004212300     0.46210    0.040275
  41      280.181    0.010990    .004212300     0.46087    0.040275
  42      280.054    0.010963    .003791070     0.45963    0.041257
  43      279.899    0.010931    .004212300     0.45944    0.041257
  44      279.807    0.010911    .003791070     0.45983    0.042240
  45      279.747    0.010899    .004212300     0.45855    0.041257
  46      279.690    0.010887    .003791070     0.45983    0.042240
  47      279.603    0.010868    .004212300     0.45853    0.040275
  48      279.496    0.010846    .004212300     0.45991    0.043222
  49      279.427    0.010831    .004212300     0.45983    0.044204
  50      279.366    0.010819    .003791070     0.46234    0.043222
  50      279.366    0.010819    .003791070     0.46234    0.043222
 
 
 
 
Selected Iteration based on _VMISC_
 
_ITER_     _AIC_      _AVERR_        _MISC_    _VAVERR_     _VMISC_
 
   0      288.603    0.012764    .003791070     0.45984    0.040275
 
 
 
 
Search # 2 FUNNEL LAYERS trial # 2 : LOGISTIC : Prelim
 
The NEURAL Procedure
 
Preliminary       Starting         Objective         Number
 Training          Random           Function           of        Terminating
    Run             Seed             Value         Iterations     Criteria
 
        1           653604406    0.018222487699           25
        2          1805272876    0.016043653218           25
        3          1442967529    0.019446415323           25
        4          1466913305    0.021618789615           25
        5          1073240799    0.020479679204           25
        6           325305996    0.018248034306           25
        7          2136509232    0.019048068873           25
        8           977813023    0.017899366447           25
        9          1009867108    0.018908410854           25
       10           313319148    0.017535853419           25
       11          1248932966    0.021262425475           25
       12           443224564    0.021556994707           25
       13            68569723    0.018916580425           25
       14          1662706190    0.032585627989           25
       15          1153017962    0.018149048195           25
       16          2057079730    0.021285496795           25
       17           809118659     0.02002847803           25
       18           163110419    0.020151181198           25
       19          1626107003    0.021636962305           25
       20          1812447560    0.022932239712           25
       21            96098578    0.017384836837           25
       22           727635218    0.017004907219           25
       23          2133842221    0.023107607937           25
       24          1646872560    0.016461833283           25
       25          2017365357     0.03486848831           25
       26          1993091049    0.016408561228           25
       27           606251567    0.018813536079           25
       28          1262335927    0.025649351466           25
       29            28168338    0.022224353682           25
       30          1185960805    0.016393164541           25
 
 
 
 
Search # 2 FUNNEL LAYERS trial # 2 : LOGISTIC : Training
 
_ITER_     _AIC_      _AVERR_        _MISC_    _VAVERR_     _VMISC_
 
   0      606.175    0.016044    .004633530     0.23082    0.043222
   1      605.879    0.015981    .004212300     0.23119    0.043222
   2      604.961    0.015788    .004633530     0.23083    0.043222
   3      604.292    0.015647    .004212300     0.23069    0.043222
   4      603.610    0.015503    .003369840     0.23088    0.043222
   5      603.425    0.015464    .003791070     0.23079    0.043222
   6      603.193    0.015416    .004633530     0.23062    0.043222
   7      602.605    0.015292    .004212300     0.23155    0.043222
   8      602.197    0.015206    .004633530     0.23144    0.043222
   9      601.611    0.015082    .004212300     0.23155    0.043222
  10      601.168    0.014989    .004212300     0.23184    0.043222
  11      600.654    0.014881    .003791070     0.23220    0.043222
  12      600.094    0.014763    .003791070     0.23381    0.043222
  13      599.371    0.014611    .003791070     0.23479    0.043222
  14      599.085    0.014550    .003791070     0.23696    0.043222
  15      598.423    0.014411    .003791070     0.23551    0.043222
  16      597.487    0.014214    .003791070     0.23598    0.043222
  17      597.098    0.014132    .004212300     0.23654    0.042240
  18      596.654    0.014038    .003791070     0.23847    0.044204
  19      596.429    0.013991    .003369840     0.23872    0.044204
  20      596.167    0.013936    .003369840     0.23863    0.042240
  21      595.996    0.013900    .003369840     0.23922    0.043222
  22      595.459    0.013787    .004212300     0.23874    0.042240
  23      594.936    0.013676    .003369840     0.23932    0.043222
  24      594.553    0.013596    .004212300     0.23842    0.042240
  25      593.955    0.013470    .003791070     0.23975    0.043222
  26      593.700    0.013416    .003791070     0.24151    0.042240
  27      593.315    0.013335    .003791070     0.24087    0.042240
  28      593.126    0.013295    .003369840     0.23999    0.042240
  29      592.738    0.013214    .003791070     0.24105    0.041257
  30      592.283    0.013118    .003369840     0.24122    0.042240
  31      591.782    0.013012    .002948610     0.24172    0.041257
  32      590.940    0.012835    .002948610     0.24165    0.040275
  33      590.206    0.012680    .003369840     0.24205    0.040275
  34      589.951    0.012627    .003369840     0.24195    0.040275
  35      589.520    0.012536    .003369840     0.24177    0.040275
  36      588.808    0.012386    .003791070     0.24179    0.041257
  37      588.478    0.012316    .003369840     0.24181    0.041257
  38      588.040    0.012224    .003369840     0.24185    0.041257
  39      587.561    0.012123    .003369840     0.24124    0.039293
  40      586.995    0.012004    .003369840     0.24156    0.040275
  41      586.784    0.011959    .003369840     0.24164    0.039293
  42      586.498    0.011899    .003369840     0.24172    0.039293
  43      586.034    0.011802    .003369840     0.24352    0.039293
  44      585.574    0.011705    .002948610     0.24648    0.040275
  45      585.057    0.011596    .003369840     0.24518    0.039293
  46      584.481    0.011475    .003369840     0.24838    0.041257
  47      583.866    0.011345    .002948610     0.24812    0.040275
  48      583.458    0.011259    .002948610     0.25002    0.040275
  49      583.223    0.011210    .002948610     0.25098    0.040275
  50      582.961    0.011154    .002948610     0.25035    0.040275
  50      582.961    0.011154    .002948610     0.25035    0.040275
 
 
 
 
Selected Iteration based on _VMISC_
 
_ITER_     _AIC_      _AVERR_        _MISC_    _VAVERR_     _VMISC_
 
  39      587.561    0.012123    .003369840     0.24124    0.039293
 
 
 
 
Search # 2 FUNNEL LAYERS trial # 3 : SINE : Prelim
 
The NEURAL Procedure
 
Preliminary       Starting         Objective         Number
 Training          Random           Function           of        Terminating
    Run             Seed             Value         Iterations     Criteria
 
        1               12345    0.086181958938           25
 
 
 
 
Search # 2 FUNNEL LAYERS trial # 3 : SINE : Training
 
_ITER_     _AIC_      _AVERR_     _MISC_     _VAVERR_     _VMISC_
 
   0      939.192    0.086182    0.023168     0.26837    0.046169
   1      931.781    0.084621    0.022325     0.27105    0.048134
   2      899.616    0.077847    0.020219     0.26344    0.048134
   3      881.975    0.074131    0.019377     0.26302    0.047151
   4      854.481    0.068341    0.021061     0.25085    0.048134
   5      828.262    0.062818    0.020640     0.24397    0.051081
   6      800.772    0.057029    0.021061     0.22404    0.045187
   7      781.385    0.052945    0.016428     0.23204    0.044204
   8      758.850    0.048199    0.016428     0.23116    0.045187
   9      749.042    0.046133    0.015164     0.23392    0.045187
  10      743.091    0.044880    0.014743     0.23825    0.044204
  11      728.916    0.041895    0.014322     0.24121    0.044204
  12      720.489    0.040120    0.013901     0.23268    0.045187
  13      706.976    0.037274    0.012637     0.23720    0.045187
  14      702.581    0.036348    0.010952     0.23563    0.045187
  15      691.533    0.034021    0.010952     0.23893    0.046169
  16      687.103    0.033088    0.011373     0.23713    0.049116
  17      680.315    0.031659    0.008425     0.23762    0.045187
  18      678.821    0.031344    0.010110     0.23722    0.045187
  19      674.597    0.030454    0.009267     0.24226    0.046169
  20      670.806    0.029656    0.009267     0.24003    0.041257
  21      666.072    0.028659    0.007582     0.24561    0.041257
  22      663.838    0.028188    0.008003     0.25358    0.043222
  23      660.918    0.027573    0.008003     0.25106    0.044204
  24      659.016    0.027173    0.007161     0.25057    0.041257
  25      656.272    0.026595    0.006740     0.24860    0.041257
  26      654.837    0.026293    0.007161     0.25253    0.042240
  27      652.741    0.025851    0.006740     0.25182    0.041257
  28      650.098    0.025294    0.005897     0.25478    0.044204
  29      646.437    0.024523    0.006740     0.26112    0.043222
  30      644.237    0.024060    0.005897     0.26822    0.043222
  31      641.476    0.023478    0.005476     0.27363    0.043222
  32      637.645    0.022672    0.006318     0.28013    0.043222
  33      636.662    0.022465    0.006740     0.29065    0.043222
  34      633.789    0.021860    0.006318     0.28837    0.042240
  35      629.823    0.021024    0.005476     0.28756    0.042240
  36      624.965    0.020001    0.005897     0.29163    0.046169
  37      622.938    0.019574    0.005897     0.29547    0.047151
  38      621.224    0.019213    0.005055     0.29262    0.046169
  39      619.304    0.018809    0.005476     0.29800    0.047151
  40      618.175    0.018571    0.004634     0.30120    0.049116
  41      616.438    0.018205    0.004634     0.30356    0.049116
  42      615.895    0.018091    0.004634     0.31079    0.048134
  43      613.599    0.017607    0.004634     0.30938    0.048134
  44      612.140    0.017300    0.005055     0.31482    0.048134
  45      610.125    0.016875    0.005055     0.31502    0.047151
  46      608.984    0.016635    0.004634     0.31363    0.047151
  47      605.991    0.016005    0.004212     0.31880    0.048134
  48      604.100    0.015607    0.003791     0.31529    0.050098
  49      601.253    0.015007    0.004212     0.31463    0.049116
  50      599.885    0.014719    0.003791     0.31357    0.049116
  50      599.885    0.014719    0.003791     0.31357    0.049116
 
 
 
 
Selected Iteration based on _VMISC_
 
_ITER_     _AIC_      _AVERR_        _MISC_    _VAVERR_     _VMISC_
 
  20      670.806    0.029656    .009267060     0.24003    0.041257
 
 
 
 
Search # 2 FUNNEL LAYERS trial # 4 : SOFTMAX : Prelim
 
The NEURAL Procedure
 
Preliminary       Starting         Objective         Number
 Training          Random           Function           of        Terminating
    Run             Seed             Value         Iterations     Criteria
 
        1               12345    0.013470546883           25
 
 
 
 
Search # 2 FUNNEL LAYERS trial # 4 : SOFTMAX : Training
 
_ITER_     _AIC_      _AVERR_        _MISC_    _VAVERR_     _VMISC_
 
   0      567.958    0.013471    .003369840     0.21218    0.042240
   1      567.352    0.013343    .002106150     0.21161    0.040275
   2      566.236    0.013108    .002106150     0.21269    0.040275
   3      565.557    0.012965    .002948610     0.21430    0.043222
   4      565.218    0.012893    .003369840     0.21511    0.043222
   5      564.252    0.012690    .002948610     0.21544    0.042240
   6      563.668    0.012567    .002527380     0.21695    0.044204
   7      562.997    0.012426    .002948610     0.21685    0.042240
   8      562.264    0.012271    .002948610     0.21503    0.039293
   9      561.867    0.012188    .002527380     0.21613    0.039293
  10      561.072    0.012020    .002527380     0.21504    0.040275
  11      560.786    0.011960    .002527380     0.21613    0.041257
  12      560.192    0.011835    .002948610     0.21539    0.040275
  13      559.506    0.011690    .002948610     0.21693    0.040275
  14      558.574    0.011494    .002948610     0.21731    0.039293
  15      558.141    0.011403    .003791070     0.21832    0.040275
  16      557.248    0.011215    .002948610     0.21841    0.038310
  17      556.371    0.011030    .002948610     0.22053    0.038310
  18      555.867    0.010924    .002948610     0.22176    0.039293
  19      555.316    0.010808    .002948610     0.22273    0.039293
  20      554.945    0.010730    .002948610     0.22365    0.038310
  21      554.377    0.010610    .002948610     0.22506    0.038310
  22      554.020    0.010535    .002948610     0.22673    0.040275
  23      553.123    0.010346    .002948610     0.22931    0.039293
  24      552.358    0.010185    .002948610     0.23274    0.038310
  25      551.888    0.010086    .002948610     0.23451    0.040275
  26      551.307    0.009963    .003369840     0.23438    0.041257
  27      550.694    0.009835    .002948610     0.24036    0.040275
  28      550.101    0.009710    .002948610     0.23974    0.040275
  29      549.389    0.009560    .003369840     0.24285    0.041257
  30      549.178    0.009515    .002948610     0.24697    0.041257
  31      548.545    0.009382    .003369840     0.24441    0.042240
  32      548.263    0.009322    .003369840     0.24967    0.043222
  33      547.459    0.009153    .002948610     0.24793    0.040275
  34      546.504    0.008952    .002106150     0.25534    0.042240
  35      545.724    0.008788    .002106150     0.25686    0.042240
  36      544.839    0.008601    .002948610     0.26061    0.044204
  37      544.396    0.008508    .002948610     0.26180    0.043222
  38      543.983    0.008421    .002106150     0.26561    0.042240
  39      543.383    0.008295    .002106150     0.26873    0.042240
  40      543.202    0.008257    .002948610     0.27227    0.042240
  41      542.560    0.008121    .002948610     0.27249    0.042240
  42      542.229    0.008052    .002106150     0.27489    0.042240
  43      541.648    0.007929    .002106150     0.27864    0.042240
  44      541.114    0.007817    .002106150     0.28785    0.044204
  45      540.440    0.007675    .002106150     0.28760    0.042240
  46      540.225    0.007629    .001263690     0.29856    0.042240
  47      539.183    0.007410    .001263690     0.29768    0.042240
  48      538.621    0.007292    .001263690     0.30294    0.042240
  49      537.980    0.007157    .001263690     0.30926    0.043222
  50      537.797    0.007118    .001684920     0.30765    0.043222
  50      537.797    0.007118    .001684920     0.30765    0.043222
 
 
 
 
Selected Iteration based on _VMISC_
 
_ITER_     _AIC_      _AVERR_        _MISC_    _VAVERR_     _VMISC_
 
  16      557.248    0.011215    .002948610     0.21841    0.038310
 
 
 
 
Search # 3 FUNNEL LAYERS trial # 1 : DIRECT : Prelim
 
The NEURAL Procedure
 
Preliminary       Starting         Objective         Number
 Training          Random           Function           of        Terminating
    Run             Seed             Value         Iterations     Criteria
 
        1               12345    0.008897300995           25
 
 
 
 
Search # 3 FUNNEL LAYERS trial # 1 : DIRECT : Training
 
_ITER_     _AIC_        _AVERR_        _MISC_    _VAVERR_     _VMISC_
 
   0      580.244    .008897301    .002948610     0.24942    0.043222
   1      580.050    .008856314    .002948610     0.24951    0.043222
   2      579.714    .008785551    .002948610     0.25023    0.043222
   3      579.484    .008737219    .002527380     0.25136    0.044204
   4      579.140    .008664740    .002527380     0.25091    0.043222
   5      578.901    .008614318    .002527380     0.25170    0.043222
   6      578.820    .008597301    .002527380     0.25089    0.042240
   7      578.647    .008560933    .002527380     0.25158    0.043222
   8      578.454    .008520214    .002527380     0.25228    0.043222
   9      578.332    .008494423    .002527380     0.25334    0.043222
  10      578.142    .008454532    .002948610     0.25448    0.042240
  11      577.978    .008419921    .002948610     0.25606    0.043222
  12      577.874    .008398127    .002948610     0.25526    0.044204
  13      577.631    .008346939    .002527380     0.25749    0.042240
  14      577.498    .008318879    .002948610     0.25684    0.042240
  15      577.311    .008279402    .002948610     0.25874    0.043222
  16      577.199    .008255802    .002948610     0.25923    0.043222
  17      576.963    .008206192    .002948610     0.25926    0.042240
  18      576.873    .008187208    .002948610     0.25948    0.042240
  19      576.689    .008148398    .002527380     0.25853    0.042240
  20      576.612    .008132334    .002527380     0.25855    0.041257
  21      576.512    .008111215    .002948610     0.25870    0.041257
  22      576.375    .008082377    .002948610     0.25961    0.041257
  23      576.270    .008060341    .002948610     0.25777    0.041257
  24      576.137    .008032284    .002948610     0.25873    0.041257
  25      575.954    .007993678    .002948610     0.25892    0.041257
  26      575.864    .007974707    .002948610     0.25949    0.041257
  27      575.649    .007929458    .002948610     0.26003    0.041257
  28      575.519    .007901992    .002948610     0.25925    0.041257
  29      575.301    .007856140    .002527380     0.26006    0.040275
  30      574.946    .007781335    .002527380     0.26176    0.041257
  31      574.804    .007751430    .002527380     0.26529    0.040275
  32      574.579    .007704110    .002527380     0.26467    0.040275
  33      574.451    .007677199    .002527380     0.26463    0.041257
  34      574.260    .007636930    .002527380     0.26541    0.041257
  35      574.140    .007611697    .002527380     0.26792    0.041257
  36      573.948    .007571213    .002527380     0.26755    0.041257
  37      573.636    .007505390    .002106150     0.26888    0.041257
  38      573.235    .007421075    .001263690     0.27175    0.041257
  39      573.013    .007374214    .001684920     0.27160    0.041257
  40      572.728    .007314171    .001263690     0.27238    0.041257
  41      571.958    .007152151    .001684920     0.27732    0.040275
  42      571.641    .007085207    .001263690     0.28044    0.041257
  43      571.250    .007002992    .001263690     0.27978    0.040275
  44      571.059    .006962703    .001263690     0.27937    0.040275
  45      570.532    .006851650    .001263690     0.28374    0.041257
  46      569.752    .006687447    .001263690     0.28540    0.041257
  47      569.355    .006603825    .001263690     0.28609    0.041257
  48      569.094    .006548920    .001263690     0.28980    0.040275
  49      568.773    .006481337    .001684920     0.29004    0.040275
  50      568.597    .006444094    .001684920     0.29314    0.040275
  50      568.597    .006444094    .001684920     0.29314    0.040275
 
 
 
 
Selected Iteration based on _VMISC_
 
_ITER_     _AIC_        _AVERR_        _MISC_    _VAVERR_     _VMISC_
 
  29      575.301    .007856140    .002527380     0.26006    0.040275
 
 
 
 
Search # 3 FUNNEL LAYERS trial # 2 : LOGISTIC : Prelim
 
The NEURAL Procedure
 
Preliminary       Starting         Objective         Number
 Training          Random           Function           of        Terminating
    Run             Seed             Value         Iterations     Criteria
 
        1          1779985752    0.016682292523           25
        2          1756397355    0.014227586889           25
        3           499845005    0.020554232326           25
        4           129205519     0.14310103788           25
        5           881709841    0.025138588376           25
        6            77914199    0.018749169268           25
        7           695603083    0.023296650081           25
        8          1858253139    0.020816637801           25
        9            70389580    0.019250421737           25
       10          1441805435    0.040842365706           25
       11          1729100622    0.057300502038           25
       12          1894525132    0.039718243393           25
       13          1332510876    0.014362437091           25
       14          1798322553    0.016864656213           25
       15           363294660    0.018402809257           25
       16           916899612    0.040090392034           25
       17           482460859    0.048404746249           25
       18          1962865965    0.028912355416           25
       19           715748007    0.012445801062           25
       20           439359316    0.021966913188           25
       21           602941539     0.04720301565           25
       22           770625055    0.018654611119           25
       23           818731987    0.025539872398           25
       24           752231176    0.041959697483           25
       25          2118373837     0.02832120529           25
       26          1078261300    0.025686540092           25
       27          1504987189    0.028583000021           25
       28           731519286    0.039202417705           25
       29          1911587304    0.014336619709           25
       30           367631241    0.016855852852           25
       31          1865458623    0.132160816441           25
       32           963446419    0.036683886549           25
 
 
 
 
Search # 3 FUNNEL LAYERS trial # 2 : LOGISTIC : Training
 
_ITER_     _AIC_      _AVERR_        _MISC_    _VAVERR_     _VMISC_
 
   0      1149.09    0.012446    .003369840     0.18798    0.038310
   1      1147.52    0.012114    .002527380     0.18862    0.041257
   2      1146.40    0.011879    .002948610     0.19064    0.041257
   3      1145.78    0.011748    .002527380     0.19322    0.039293
   4      1143.52    0.011273    .002948610     0.20054    0.039293
   5      1141.46    0.010839    .002948610     0.20657    0.039293
   6      1139.92    0.010513    .002106150     0.22266    0.041257
   7      1139.02    0.010324    .002527380     0.22538    0.040275
   8      1138.06    0.010121    .002106150     0.23121    0.041257
   9      1137.57    0.010018    .002106150     0.23192    0.038310
  10      1136.55    0.009804    .002527380     0.23590    0.038310
  11      1136.32    0.009755    .002527380     0.23565    0.038310
  12      1136.14    0.009718    .002527380     0.23494    0.038310
  13      1136.10    0.009710    .002106150     0.23532    0.040275
  14      1135.77    0.009641    .002106150     0.23401    0.039293
  15      1135.59    0.009602    .002527380     0.23373    0.038310
  16      1135.19    0.009518    .002106150     0.23264    0.038310
  17      1135.12    0.009503    .002527380     0.23275    0.038310
  18      1135.10    0.009498    .002527380     0.23300    0.038310
  19      1135.07    0.009492    .002106150     0.23322    0.038310
  20      1134.97    0.009472    .002527380     0.23420    0.038310
  21      1134.93    0.009462    .002527380     0.23407    0.038310
  22      1134.75    0.009425    .002527380     0.23484    0.038310
  23      1134.26    0.009322    .002106150     0.23675    0.039293
  24      1134.15    0.009299    .002106150     0.23747    0.040275
  25      1133.33    0.009127    .002527380     0.24092    0.041257
  26      1133.13    0.009084    .002106150     0.24554    0.040275
  27      1133.05    0.009067    .002106150     0.24618    0.040275
  28      1132.18    0.008884    .002106150     0.24617    0.041257
  29      1132.15    0.008878    .002106150     0.24649    0.041257
  30      1131.99    0.008844    .002527380     0.24622    0.040275
  31      1131.40    0.008719    .001684920     0.24522    0.040275
  32      1131.18    0.008673    .002106150     0.24528    0.041257
  33      1131.07    0.008650    .002527380     0.24554    0.043222
  34      1130.57    0.008544    .002527380     0.24703    0.042240
  35      1130.49    0.008527    .002948610     0.24682    0.041257
  36      1130.39    0.008507    .002527380     0.24659    0.042240
  37      1130.35    0.008497    .002527380     0.24682    0.043222
  38      1130.17    0.008460    .001684920     0.24735    0.042240
  39      1129.96    0.008417    .001263690     0.24850    0.042240
  40      1129.87    0.008397    .002106150     0.24904    0.042240
  41      1129.75    0.008373    .002527380     0.24967    0.041257
  42      1129.12    0.008239    .002106150     0.25061    0.041257
  43      1129.03    0.008220    .002106150     0.25160    0.041257
  44      1128.86    0.008186    .001684920     0.25185    0.041257
  45      1128.83    0.008177    .001684920     0.25214    0.041257
  46      1128.72    0.008155    .002106150     0.25170    0.041257
  47      1128.34    0.008076    .002106150     0.25248    0.041257
  48      1128.16    0.008036    .001263690     0.25563    0.041257
  49      1128.12    0.008029    .001684920     0.25612    0.041257
  50      1128.03    0.008009    .001684920     0.25646    0.042240
  50      1128.03    0.008009    .001684920     0.25646    0.042240
 
 
 
 
Selected Iteration based on _VMISC_
 
_ITER_     _AIC_      _AVERR_        _MISC_    _VAVERR_     _VMISC_
 
   0      1149.09    0.012446    .003369840     0.18798    0.038310
 
 
 
 
Search # 3 FUNNEL LAYERS trial # 3 : SINE : Prelim
 
The NEURAL Procedure
 
Preliminary       Starting         Objective         Number
 Training          Random           Function           of        Terminating
    Run             Seed             Value         Iterations     Criteria
 
        1          1779985752    0.009381811216           25
        2          1756397355     0.01118340142           25
        3           499845005    0.012403455277           25
        4           129205519    0.010007600508           25
        5           881709841    0.023357838832           25
        6            77914199    0.009079290717           25
        7           695603083    0.008957226256           25
        8          1858253139    0.010388395147           25
        9            70389580    0.008584510422           25
       10          1441805435    0.012541031722           25
       11          1729100622    0.009662748883           25
       12          1894525132    0.010670076813           25
       13          1332510876    0.010659575632           25
       14          1798322553    0.008565103072           25
       15           363294660    0.008269857137           25
       16           916899612    0.009070465307           25
       17           482460859    0.009673681546           25
       18          1962865965    0.008877033267           25
       19           715748007    0.009951586593           25
       20           439359316    0.008918944185           25
       21           602941539    0.009347161222           25
       22           770625055    0.009253323129           25
       23           818731987     0.01037297071           25
       24           752231176    0.009633007728           25
       25          2118373837     0.00724243916           25
       26          1078261300     0.00847610159           25
       27          1504987189    0.015969898003           25
       28           731519286    0.008527037189           25
       29          1911587304     0.01109602829           25
       30           367631241    0.008256244729           25
       31          1865458623    0.009192124033           25
       32           963446419    0.009356758414           25
 
 
 
 
Search # 3 FUNNEL LAYERS trial # 3 : SINE : Training
 
_ITER_     _AIC_        _AVERR_        _MISC_    _VAVERR_     _VMISC_
 
   0      1124.39    .007242439    .002527380     0.41627    0.043222
   1      1124.26    .007216647    .002527380     0.41689    0.043222
   2      1124.23    .007210035    .002527380     0.41657    0.043222
   3      1124.23    .007209349    .002527380     0.41648    0.043222
   4      1124.20    .007203271    .002527380     0.41675    0.043222
   5      1124.20    .007203208    .002527380     0.41678    0.043222
   6      1124.18    .007198949    .002527380     0.41655    0.043222
   7      1124.16    .007195419    .002527380     0.41686    0.043222
   8      1124.14    .007191078    .002527380     0.41664    0.043222
   9      1124.14    .007190772    .002527380     0.41658    0.043222
  10      1124.12    .007186956    .002527380     0.41682    0.043222
  11      1124.12    .007186956    .002527380     0.41682    0.043222
  12      1124.11    .007183212    .002527380     0.41664    0.043222
  13      1124.09    .007179806    .002527380     0.41695    0.043222
  14      1124.07    .007176168    .002527380     0.41672    0.043222
  15      1124.06    .007173200    .002527380     0.41705    0.043222
  16      1124.05    .007171381    .002527380     0.41669    0.043222
  17      1124.02    .007165208    .002527380     0.41701    0.043222
  18      1124.02    .007164766    .002527380     0.41711    0.043222
  19      1124.00    .007161167    .002527380     0.41692    0.043222
  20      1123.99    .007157861    .002527380     0.41726    0.043222
  21      1123.97    .007155612    .002527380     0.41689    0.043222
  22      1123.95    .007149717    .002527380     0.41721    0.043222
  23      1123.94    .007149166    .002527380     0.41732    0.043222
  24      1123.93    .007145534    .002527380     0.41713    0.043222
  25      1123.91    .007142186    .002527380     0.41749    0.043222
  26      1123.90    .007139659    .002527380     0.41712    0.043222
  27      1123.87    .007134167    .002527380     0.41745    0.043222
  28      1123.87    .007134033    .002527380     0.41750    0.043222
  29      1123.86    .007130880    .002527380     0.41734    0.043222
  30      1123.84    .007127958    .002527380     0.41766    0.043222
  31      1123.82    .007123972    .002527380     0.41749    0.043222
  32      1123.82    .007121988    .002527380     0.41738    0.043222
  33      1123.78    .007115109    .002527380     0.41774    0.043222
  34      1123.77    .007111916    .002527380     0.41761    0.043222
  35      1123.77    .007111808    .002527380     0.41759    0.043222
  36      1123.75    .007107863    .002527380     0.41784    0.043222
  37      1123.75    .007107862    .002527380     0.41785    0.043222
  38      1123.73    .007104195    .002527380     0.41773    0.043222
  39      1123.71    .007100781    .002527380     0.41804    0.043222
  40      1123.70    .007098376    .002527380     0.41782    0.043222
  41      1123.69    .007095779    .002527380     0.41822    0.043222
  42      1123.68    .007092855    .002527380     0.41791    0.043222
  43      1123.67    .007091252    .002527380     0.41838    0.043222
  44      1123.64    .007085616    .002527380     0.41812    0.043222
  45      1123.64    .007085241    .002527380     0.41808    0.043222
  46      1123.63    .007082101    .002527380     0.41831    0.043222
  47      1123.63    .007082101    .002527380     0.41831    0.043222
  48      1123.61    .007078972    .002527380     0.41819    0.043222
  49      1123.60    .007076056    .002527380     0.41849    0.043222
  50      1123.58    .007073276    .002527380     0.41830    0.043222
  50      1123.58    .007073276    .002527380     0.41830    0.043222
 
 
 
 
Selected Iteration based on _VMISC_
 
_ITER_     _AIC_        _AVERR_        _MISC_    _VAVERR_     _VMISC_
 
   0      1124.39    .007242439    .002527380     0.41627    0.043222
 
 
 
 
Search # 3 FUNNEL LAYERS trial # 4 : SOFTMAX : Prelim
 
The NEURAL Procedure
 
Preliminary       Starting         Objective         Number
 Training          Random           Function           of        Terminating
    Run             Seed             Value         Iterations     Criteria
 
        1           967611161    0.012707462248           25
        2          1961082054     0.01835750606           25
        3          1073240799    0.012224423093           25
        4          1822595591    0.095320538391           25
        5           963441619    0.030942284412           25
        6           313319148    0.037274954689           25
        7           932035661     0.01321642043           25
        8           384118380    0.019147992827           25
        9          1153017962    0.030422904066           25
       10           320494460    0.012042455854           25
       11           322204124    0.424822045199            6      GCONV
       12          1812447560    0.013172836605           25
       13          2110286737    0.014270917294           25
       14          1721516909    0.041692609415           25
       15          2017365357    0.145635944936           25
       16          1501816644     0.02937669519           25
       17           656391689    0.054131331823           25
       18          1185960805    0.035818937497           25
       19          1436629562    0.018907326178           25
       20           332299952    0.057777138402           25
       21          1971561506    0.014483472698           25
       22           280110736    0.013130537952           25
       23          1633245755    0.045104407794           25
       24          1152542473    0.018850759398           25
       25           881782459    0.020662620988           25
       26          1176578702    0.017404875646           25
       27           246747632    0.424822184546            7      GCONV
       28          1657772218    0.104124690948           25
       29           733591023    0.424765698622           14      FCONV
       30           192025240    0.424821819708            6      GCONV
       31           359558501    0.424822100516            5      GCONV
       32          1822717946    0.140860830241           25
 
 
 
 
Search # 3 FUNNEL LAYERS trial # 4 : SOFTMAX : Training
 
_ITER_     _AIC_      _AVERR_        _MISC_    _VAVERR_     _VMISC_
 
   0      1121.18    0.012042    .002948610     0.29459    0.041257
   1      1119.99    0.011792    .002948610     0.29607    0.041257
   2      1119.64    0.011718    .002948610     0.29528    0.041257
   3      1118.90    0.011563    .002527380     0.29449    0.041257
   4      1118.58    0.011495    .002948610     0.29563    0.041257
   5      1117.53    0.011274    .002948610     0.29597    0.041257
   6      1116.94    0.011150    .002948610     0.29694    0.041257
   7      1115.96    0.010944    .002527380     0.29350    0.040275
   8      1115.26    0.010796    .002948610     0.29446    0.040275
   9      1114.38    0.010610    .002527380     0.29372    0.040275
  10      1113.70    0.010467    .002527380     0.29372    0.040275
  11      1113.25    0.010374    .002106150     0.29107    0.040275
  12      1112.31    0.010174    .002527380     0.29225    0.039293
  13      1110.40    0.009773    .002948610     0.29737    0.039293
  14      1109.43    0.009568    .002106150     0.29669    0.039293
  15      1106.60    0.008972    .002106150     0.29717    0.039293
  16      1106.01    0.008848    .002106150     0.29917    0.040275
  17      1103.90    0.008404    .001263690     0.30482    0.041257
  18      1102.54    0.008117    .001263690     0.30863    0.042240
  19      1102.14    0.008033    .001263690     0.31095    0.042240
  20      1101.01    0.007795    .001263690     0.30909    0.042240
  21      1100.25    0.007634    .001263690     0.31068    0.042240
  22      1100.10    0.007603    .001263690     0.31034    0.042240
  23      1100.00    0.007581    .001263690     0.31102    0.042240
  24      1099.92    0.007565    .001263690     0.31071    0.042240
  25      1099.86    0.007552    .001263690     0.31020    0.042240
  26      1099.69    0.007517    .001263690     0.31020    0.042240
  27      1099.59    0.007495    .001263690     0.31072    0.042240
  28      1098.62    0.007292    .001263690     0.31186    0.043222
  29      1098.43    0.007251    .001263690     0.31281    0.044204
  30      1098.16    0.007194    .001263690     0.31384    0.043222
  31      1097.88    0.007136    .001684920     0.31747    0.042240
  32      1096.95    0.006941    .001263690     0.32296    0.041257
  33      1096.62    0.006870    .001263690     0.32722    0.041257
  34      1095.57    0.006650    .001263690     0.32868    0.041257
  35      1095.42    0.006618    .001263690     0.33127    0.041257
  36      1094.79    0.006485    .000842460     0.33229    0.042240
  37      1094.30    0.006383    .001263690     0.33242    0.041257
  38      1093.85    0.006287    .001263690     0.33460    0.041257
  39      1092.77    0.006060    .000842460     0.33729    0.042240
  40      1091.62    0.005816    .000842460     0.34027    0.043222
  41      1090.84    0.005653    .001263690     0.34252    0.044204
  42      1090.60    0.005601    .000842460     0.34249    0.044204
  43      1090.01    0.005478    .000842460     0.34632    0.044204
  44      1089.90    0.005456    .000842460     0.34642    0.044204
  45      1089.78    0.005429    .000842460     0.35403    0.042240
  46      1089.70    0.005413    .000842460     0.35424    0.042240
  47      1089.50    0.005370    .000842460     0.35593    0.042240
  48      1089.34    0.005337    .000842460     0.35470    0.043222
  49      1088.83    0.005230    .000842460     0.35359    0.043222
  50      1088.51    0.005163    .000842460     0.35587    0.043222
  50      1088.51    0.005163    .000842460     0.35587    0.043222
 
 
 
 
Selected Iteration based on _VMISC_
 
_ITER_     _AIC_      _AVERR_        _MISC_    _VAVERR_     _VMISC_
 
  12      1112.31    0.010174    .002527380     0.29225    0.039293
 
 
 
 
Final Training Prelim
 
The NEURAL Procedure
 
Preliminary       Starting         Objective         Number
 Training          Random           Function           of        Terminating
    Run             Seed             Value         Iterations     Criteria
 
        1               12345    0.008935819958           25
 
 
 
 
Final Training Training
 
_ITER_     _AIC_        _AVERR_        _MISC_    _VAVERR_     _VMISC_
 
   0      546.427    .008935820    .002527380     0.25108    0.043222
   1      546.378    .008925357    .002527380     0.25096    0.043222
   2      546.147    .008876788    .002527380     0.25152    0.043222
   3      545.980    .008841627    .002527380     0.25191    0.043222
   4      545.787    .008801007    .002527380     0.25244    0.044204
   5      545.673    .008776924    .002527380     0.25263    0.042240
   5      545.673    .008776924    .002527380     0.25263    0.042240
 
 
 
 
Selected Iteration based on _VMISC_
 
_ITER_     _AIC_        _AVERR_        _MISC_    _VAVERR_     _VMISC_
 
   5      545.673    .008776924    .002527380     0.25263    0.042240
 
 
 
 
Final Training History
 
                             _                                   _
                             s           _                       V       _
       _           _         t      _    A       _               A       V
       s           f         a      i    V       M       _       V       M
       t           u         t      t    E       I       A       E       I
       e           n         u      e    R       S       I       R       S
       p           c         s      r    R       C       C       R       C
       _           _         _      _    _       _       _       _       _
 
FUNNEL LAYERS 1 DIRECT   initial    0 0.42482 0.15122 2053.06 0.42661 0.15226
FUNNEL LAYERS 1 DIRECT   candidate  1 0.18670 0.06276  922.46 0.19902 0.06778
FUNNEL LAYERS 1 LOGISTIC candidate  1 0.07297 0.02612  576.48 0.12977 0.05010
FUNNEL LAYERS 1 SINE     candidate 50 0.05333 0.01853  483.23 0.11752 0.04322
FUNNEL LAYERS 1 SOFTMAX  candidate 32 0.01358 0.00337  258.49 0.46288 0.04126
FUNNEL LAYERS 1 SOFTMAX  keep      32 0.01358 0.00337  258.49 0.46288 0.04126
FUNNEL LAYERS 2 DIRECT   candidate  0 0.01276 0.00379  288.60 0.45984 0.04028
FUNNEL LAYERS 2 LOGISTIC candidate 39 0.01212 0.00337  587.56 0.24124 0.03929
FUNNEL LAYERS 2 SINE     reject    20 0.02966 0.00927  670.81 0.24003 0.04126
FUNNEL LAYERS 2 SOFTMAX  candidate 16 0.01121 0.00295  557.25 0.21841 0.03831
FUNNEL LAYERS 2 SOFTMAX  keep      16 0.01121 0.00295  557.25 0.21841 0.03831
FUNNEL LAYERS 3 DIRECT   reject    29 0.00786 0.00253  575.30 0.26006 0.04028
FUNNEL LAYERS 3 LOGISTIC reject     0 0.01245 0.00337 1149.09 0.18798 0.03831
FUNNEL LAYERS 3 SINE     reject     0 0.00724 0.00253 1124.39 0.41627 0.04322
FUNNEL LAYERS 3 SOFTMAX  reject    12 0.01017 0.00253 1112.31 0.29225 0.03929
                         Final      5 0.00878 0.00253  545.67 0.25263 0.04224
 
 
 
 
Final Model
Stopping: Termination criteria were satisfied: overfitting based on _VMISC_
 
_func_      _AVERR_    _VAVERR_    neurons
 
SOFTMAX    0.013582     0.46288        6
SOFTMAX    0.011215     0.21841        6
                                   =======
                                      12


*------------------------------------------------------------*
* Score Output
*------------------------------------------------------------*


*------------------------------------------------------------*
* Report Output
*------------------------------------------------------------*
 
 
 
 
Fit Statistics
 
Target=DepVar Target Label=DepVar
 
   Fit
Statistics    Statistics Label                     Train    Validation
 
 _DFT_        Total Degrees of Freedom           2374.00          .
 _DFE_        Degrees of Freedom for Error       2122.00          .
 _DFM_        Model Degrees of Freedom            252.00          .
 _NW_         Number of Estimated Weights         252.00          .
 _AIC_        Akaike's Information Criterion      545.67          .
 _SBC_        Schwarz's Bayesian Criterion       2000.30          .
 _ASE_        Average Squared Error                 0.00         0.04
 _MAX_        Maximum Absolute Error                0.96         1.00
 _DIV_        Divisor for ASE                    4748.00      2036.00
 _NOBS_       Sum of Frequencies                 2374.00      1018.00
 _RASE_       Root Average Squared Error            0.05         0.20
 _SSE_        Sum of Squared Errors                 9.94        78.17
 _SUMW_       Sum of Case Weights Times Freq     4748.00      2036.00
 _FPE_        Final Prediction Error                0.00          .
 _MSE_        Mean Squared Error                    0.00         0.04
 _RFPE_       Root Final Prediction Error           0.05          .
 _RMSE_       Root Mean Squared Error               0.05         0.20
 _AVERR_      Average Error Function                0.01         0.25
 _ERR_        Error Function                       41.67       514.36
 _MISC_       Misclassification Rate                0.00         0.04
 _WRONG_      Number of Wrong Classifications       6.00        43.00
 
 
 
 
Classification Table
 
Data Role=TRAIN Target Variable=DepVar Target Label=DepVar
 
                       Target        Outcome     Frequency       Total
Target    Outcome    Percentage    Percentage      Count      Percentage
 
  0          0         99.8017       99.9007        2013        84.7936
  1          0          0.1983        1.1142           4         0.1685
  0          1          0.5602        0.0993           2         0.0842
  1          1         99.4398       98.8858         355        14.9537
 
 
Data Role=VALIDATE Target Variable=DepVar Target Label=DepVar
 
                       Target        Outcome     Frequency       Total
Target    Outcome    Percentage    Percentage      Count      Percentage
 
  0          0         97.7855       97.2190        839         82.4165
  1          0          2.2145       12.2581         19          1.8664
  0          1         15.0000        2.7810         24          2.3576
  1          1         85.0000       87.7419        136         13.3595
 
 
 
 
Event Classification Table
 
Data Role=TRAIN Target=DepVar Target Label=DepVar
 
  False       True        False       True
Negative    Negative    Positive    Positive
 
    4         2013          2          355
 
 
Data Role=VALIDATE Target=DepVar Target Label=DepVar
 
  False       True        False       True
Negative    Negative    Positive    Positive
 
   19          839         24          136
 
 
 
 
Assessment Score Rankings
 
Data Role=TRAIN Target Variable=DepVar Target Label=DepVar
 
                                                                                    Mean
                            Cumulative       %      Cumulative     Number of     Posterior
Depth      Gain     Lift       Lift      Response   % Response   Observations   Probability
 
   5    561.281   6.61281     6.61281     100.000     100.000         119         0.99975
  10    561.281   6.61281     6.61281     100.000     100.000         119         0.99973
  15    557.577   6.50167     6.57577      98.319      99.440         119         0.96025
  20    399.789   0.22416     4.99789       3.390      75.579         118         0.05801
  25    299.663   0.00000     3.99663       0.000      60.438         119         0.00065
  30    232.959   0.00000     3.32959       0.000      50.351         119         0.00014
  35    185.680   0.00000     2.85680       0.000      43.201         118         0.00011
  40    149.895   0.00000     2.49895       0.000      37.789         119         0.00010
  45    122.077   0.00000     2.22077       0.000      33.583         119         0.00010
  50    100.000   0.00000     2.00000       0.000      30.244         118         0.00010
  55     81.776   0.00000     1.81776       0.000      27.489         119         0.00010
  60     66.596   0.00000     1.66596       0.000      25.193         119         0.00010
  65     53.756   0.00000     1.53756       0.000      23.251         119         0.00010
  70     42.840   0.00000     1.42840       0.000      21.600         118         0.00010
  75     33.296   0.00000     1.33296       0.000      20.157         119         0.00010
  80     24.947   0.00000     1.24947       0.000      18.895         119         0.00010
  85     17.641   0.00000     1.17641       0.000      17.790         118         0.00010
  90     11.090   0.00000     1.11090       0.000      16.799         119         0.00010
  95      5.230   0.00000     1.05230       0.000      15.913         119         0.00010
 100      0.000   0.00000     1.00000       0.000      15.122         118         0.00009
 
 
Data Role=VALIDATE Target Variable=DepVar Target Label=DepVar
 
                                                                                    Mean
                            Cumulative       %      Cumulative     Number of     Posterior
Depth      Gain     Lift       Lift      Response   % Response   Observations   Probability
 
   5    543.896   6.43896     6.43896     98.0392     98.0392         51          0.99975
  10    524.579   6.05262     6.24579     92.1569     95.0980         51          0.99974
  15    462.336   4.37849     5.62336     66.6667     85.6209         51          0.95963
  20    357.166   1.41657     4.57166     21.5686     69.6078         51          0.13053
  25    276.035   0.51512     3.76035      7.8431     57.2549         51          0.00049
  30    219.802   0.38634     3.19802      5.8824     48.6928         51          0.00013
  35    179.635   0.38634     2.79635      5.8824     42.5770         51          0.00011
  40    146.290   0.12878     2.46290      1.9608     37.5000         51          0.00010
  45    118.925   0.00000     2.18925      0.0000     33.3333         51          0.00010
  50     98.710   0.13135     1.98710      2.0000     30.2554         50          0.00010
  55     80.613   0.00000     1.80613      0.0000     27.5000         51          0.00010
  60     65.537   0.00000     1.65537      0.0000     25.2046         51          0.00010
  65     52.784   0.00000     1.52784      0.0000     23.2628         51          0.00010
  70     41.856   0.00000     1.41856      0.0000     21.5989         51          0.00010
  75     32.386   0.00000     1.32386      0.0000     20.1571         51          0.00010
  80     24.102   0.00000     1.24102      0.0000     18.8957         51          0.00010
  85     16.794   0.00000     1.16794      0.0000     17.7829         51          0.00010
  90     10.298   0.00000     1.10298      0.0000     16.7939         51          0.00010
  95      4.487   0.00000     1.04487      0.0000     15.9091         51          0.00009
 100      0.000   0.13135     1.00000      2.0000     15.2259         50          0.00009
 
 
 
 
Assessment Score Distribution
 
Data Role=TRAIN Target Variable=DepVar Target Label=DepVar
 
 Posterior     Number                     Mean
Probability      of      Number of     Posterior
   Range       Events    Nonevents    Probability    Percentage
 
 0.95-1.00       334           1        0.99637        14.1112
 0.90-0.95        12           0        0.91992         0.5055
 0.85-0.90         4           0        0.86802         0.1685
 0.80-0.85         1           0        0.80942         0.0421
 0.65-0.70         1           0        0.67300         0.0421
 0.60-0.65         2           0        0.62936         0.0842
 0.55-0.60         1           1        0.58638         0.0842
 0.45-0.50         0           1        0.45261         0.0421
 0.40-0.45         1           1        0.43864         0.0842
 0.35-0.40         1           0        0.38887         0.0421
 0.25-0.30         1           0        0.26363         0.0421
 0.20-0.25         0           2        0.24187         0.0842
 0.15-0.20         0           3        0.17292         0.1264
 0.10-0.15         0          11        0.12037         0.4634
 0.05-0.10         1          18        0.07105         0.8003
 0.00-0.05         0        1977        0.00073        83.2772
 
 
Data Role=VALIDATE Target Variable=DepVar Target Label=DepVar
 
 Posterior     Number                     Mean
Probability      of      Number of     Posterior
   Range       Events    Nonevents    Probability    Percentage
 
 0.95-1.00       123         19         0.99798        13.9489
 0.90-0.95         3          0         0.93231         0.2947
 0.85-0.90         2          0         0.85821         0.1965
 0.80-0.85         0          1         0.83897         0.0982
 0.75-0.80         3          1         0.77545         0.3929
 0.70-0.75         2          1         0.73517         0.2947
 0.65-0.70         1          0         0.66258         0.0982
 0.60-0.65         0          1         0.63174         0.0982
 0.55-0.60         0          1         0.59001         0.0982
 0.50-0.55         2          0         0.52111         0.1965
 0.45-0.50         1          0         0.47961         0.0982
 0.40-0.45         1          0         0.44728         0.0982
 0.20-0.25         2          0         0.20950         0.1965
 0.15-0.20         0          1         0.16686         0.0982
 0.10-0.15         0          2         0.11356         0.1965
 0.05-0.10         0          2         0.08718         0.1965
 0.00-0.05        15        834         0.00054        83.3988
